{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7320b295-8af7-43a5-a440-48e76606f6fe",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> **INVESTMENT GRADE FIXED INCOME ANALYSIS** </center>\n",
    "\n",
    "----\n",
    "# <center> **BUILDING A FIXED INCOME VALUATION PLATFORM** </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c1a48-5282-411b-bc59-657c1c04099b",
   "metadata": {},
   "source": [
    "# Fixed Income Valuation Mini-Platform (Python)\n",
    "\n",
    "## Objective\n",
    "Build a production-grade fixed income valuation mini-platform in Python that mirrors the core workflow of an institutional valuation team pricing large corporate bond inventories daily.\n",
    "\n",
    "The platform will demonstrate:\n",
    "- Risk-free curve construction via bootstrapping (T-bills + Treasury notes)\n",
    "- Fixed-rate bond pricing (clean/dirty, accrued interest, settlement)\n",
    "- Corporate bond pricing using spread-over-curve discounting\n",
    "- Risk measures: duration, modified duration, convexity, DV01, spread duration\n",
    "- Scenario analysis: rate shocks (parallel + twists) and spread shocks\n",
    "- Vectorized portfolio pricing (20+ bonds) with quality control and validation\n",
    "- Modular, production-style architecture and interview-ready explanations\n",
    "\n",
    "This project is designed to be defensible in a Pricing Direct Evaluator / Fixed Income Valuation interview context.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Modeling Conventions \n",
    "We will explicitly define conventions because pricing is convention-sensitive.\n",
    "\n",
    "### Time and Discounting\n",
    "We represent the curve primarily via discount factors $D(t)$.\n",
    "For a continuously compounded zero rate $z(t)$ and year fraction $\\tau(t)$:\n",
    "\n",
    "$$\n",
    "D(t) = e^{-z(t)\\tau(t)}\n",
    "$$\n",
    "\n",
    "We bootstrap discount factors at instrument maturities and interpolate between knots.\n",
    "\n",
    "### Bills (Money-Market Simple Yield)\n",
    "Given a bill quote $y$ (simple yield) and year fraction $\\tau$:\n",
    "\n",
    "$$\n",
    "D(T) = \\frac{1}{1 + y\\tau}\n",
    "$$\n",
    "\n",
    "### Notes (Par Yield Bootstrapping)\n",
    "For a Treasury note with par yield $c$, coupon frequency $m=2$,\n",
    "coupon per period $\\frac{c}{m}$, and cashflow dates $t_1,\\dots,t_n$,\n",
    "par pricing implies:\n",
    "\n",
    "$$\n",
    "1 = \\sum_{i=1}^{n}\\frac{c}{m}D(t_i) + D(t_n)\n",
    "$$\n",
    "\n",
    "Solving for the final discount factor:\n",
    "\n",
    "$$\n",
    "D(t_n) = \\frac{1 - \\sum_{i=1}^{n-1}\\frac{c}{m}D(t_i)}{1 + \\frac{c}{m}}\n",
    "$$\n",
    "\n",
    "### Interpolation Choice (Default)\n",
    "Default interpolation: linear interpolation of $\\log D(t)$.\n",
    "\n",
    "Reason:\n",
    "- Guarantees strictly positive discount factors\n",
    "- More stable than interpolating yields directly\n",
    "- Reduces overshoot risk relative to unconstrained cubic splines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701dd68-a7d2-4876-8a9d-9f30b03873d2",
   "metadata": {},
   "source": [
    "# Fixed Income Valuation Mini-Platform\n",
    "\n",
    "## Project Objective\n",
    "\n",
    "This project builds a fixed income valuation and risk analytics engine in Python. The objective is not merely to price bonds, but to construct a complete valuation infrastructure capable of:\n",
    "\n",
    "- Yield curve construction\n",
    "- Clean and dirty bond pricing\n",
    "- Corporate spread modeling\n",
    "- Sensitivity analysis (DV01, convexity, key rate duration)\n",
    "- Spread risk measurement\n",
    "- Scenario stress testing\n",
    "- Portfolio-level risk aggregation\n",
    "- Internal consistency validation\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Project Matters\n",
    "\n",
    "In institutional environments (investment banks, asset managers, risk teams), fixed income valuation requires:\n",
    "\n",
    "1. Arbitrage-free yield curve construction  \n",
    "2. Settlement-aware pricing mechanics  \n",
    "3. Accurate accrued interest and clean/dirty decomposition  \n",
    "4. Robust sensitivity calculations  \n",
    "5. Scenario-based stress testing  \n",
    "6. Reconciliation between risk metrics and scenario results  \n",
    "7. Scalability to large bond portfolios  \n",
    "\n",
    "This project implements all of the above in a modular and production-oriented manner. The mini valuation engine built in this project could be extended to price millions of bonds daily.\n",
    "\n",
    "---\n",
    "\n",
    "## What Has Been Built\n",
    "\n",
    "### 1. Yield Curve Construction\n",
    "\n",
    "- Bootstrapped zero-coupon yield curve from Treasury bills and notes\n",
    "- Log-linear interpolation in discount factor space\n",
    "- Monotonic discount factor validation\n",
    "- Continuously compounded zero rate extraction\n",
    "- Settlement-adjusted discounting\n",
    "\n",
    "This ensures arbitrage-free and stable curve construction.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Bond Pricing Engine\n",
    "\n",
    "- Fixed-rate semiannual coupon bonds\n",
    "- Clean and dirty pricing\n",
    "- Accrued interest under 30/360 and ACT conventions\n",
    "- Settlement-adjusted discount factors\n",
    "- Vectorized pricing across portfolios\n",
    "\n",
    "Pricing follows:\n",
    "\n",
    "$$\n",
    "P = \\sum_i CF_i \\cdot \\frac{D(t_i)}{D(s)}\n",
    "$$\n",
    "\n",
    "where $s$ is settlement date.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Risk Measures\n",
    "\n",
    "- Parallel DV01 (finite difference)\n",
    "- Convexity (second-order finite difference)\n",
    "- Linear vs nonlinear validation\n",
    "- Key Rate Duration (KRD) using partition-of-unity hat basis functions\n",
    "- Reconciliation of KRD sum to parallel DV01\n",
    "\n",
    "This ensures internal risk consistency:\n",
    "\n",
    "$$\n",
    "\\sum_k KRD_k \\approx DV01_{\\text{parallel}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Corporate Bond Extension\n",
    "\n",
    "- Constant Z-spread applied to **all cashflows**\n",
    "- Spread-adjusted discounting:\n",
    "\n",
    "$$\n",
    "D_{corp}(t_i) = \\frac{D(t_i)}{D(s)} \\cdot e^{-s \\cdot \\tau(s, t_i)}\n",
    "$$\n",
    "\n",
    "- Spread DV01\n",
    "- Spread duration\n",
    "- Spread shock scenarios\n",
    "\n",
    "This models credit risk consistently across the entire cashflow stream.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Scenario Analysis\n",
    "\n",
    "- Parallel rate shocks (±25bp, ±50bp)\n",
    "- Steepener and flattener curve shocks\n",
    "- Spread widening scenarios\n",
    "- Combined rate + spread stress grid\n",
    "\n",
    "Scenario P&L reconciles with sensitivity approximations, validating implementation correctness.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Portfolio Risk Dashboard\n",
    "\n",
    "- Total market value\n",
    "- Parallel DV01\n",
    "- Spread DV01\n",
    "- Key rate bucket decomposition\n",
    "- Concentration analysis (top risk contributors)\n",
    "- Scenario impact summaries\n",
    "\n",
    "---\n",
    "\n",
    "## Relevance to Institutional Valuation Teams\n",
    "\n",
    "This project directly demonstrates competencies required in:\n",
    "\n",
    "- Pricing Direct Evaluation\n",
    "- Market Risk Analytics\n",
    "- Model Validation\n",
    "- Fixed Income Quantitative Research\n",
    "- Valuation Control\n",
    "\n",
    "It shows understanding of:\n",
    "\n",
    "- Discount curve mechanics\n",
    "- Credit spread modeling\n",
    "- Risk reconciliation\n",
    "- Sensitivity validation\n",
    "- Term structure decomposition\n",
    "- Stress scenario interpretation\n",
    "\n",
    "Most importantly, it demonstrates the ability to design valuation infrastructure — not just compute prices.\n",
    "\n",
    "---\n",
    "\n",
    "## Design Philosophy\n",
    "\n",
    "The platform was built with production principles in mind:\n",
    "\n",
    "- Modular architecture\n",
    "- Clear separation of curve, pricing, risk, and scenario logic\n",
    "- Vectorized portfolio computation\n",
    "- Defensive data validation\n",
    "- Reconciliation diagnostics\n",
    "\n",
    "The result is a scalable valuation framework that can be extended to:\n",
    "\n",
    "- OAS modeling\n",
    "- Stochastic interest rate models\n",
    "- Large-scale portfolio processing\n",
    "- Regulatory risk reporting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e6010b2-000e-496c-b09e-0e92badf5a85",
   "metadata": {},
   "source": [
    "## Repository Structure\n",
    "fixed_income_engine/\n",
    "│\n",
    "├── curves.py # Curve instruments, bootstrapping, interpolation, curve object\n",
    "├── bonds.py # Bond definition, cashflows, pricing, accrued interest\n",
    "├── risk.py # Duration/convexity/DV01/spread duration + validations\n",
    "├── scenarios.py # Rate/spread shocks and scenario P&L reports\n",
    "├── portfolio.py # Vectorized pricing across portfolios + QC flags\n",
    "├── utils.py # Day count, date schedules, validation, shared helpers\n",
    "└── main.py # Example runner: build curve, price portfolio, run scenarios"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7f8b4a0-bdd1-4499-9208-1b72b221cd16",
   "metadata": {},
   "source": [
    ".yaml file\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation Roadmap\n",
    "\n",
    "### Step 0 — Environment + Project Skeleton\n",
    "- Create a dedicated Python environment\n",
    "- Install NumPy / pandas / SciPy\n",
    "- Create module skeleton and notebooks folder\n",
    "- Define coding standards and validation approach\n",
    "\n",
    "### Step 1 — Yield Curve Construction (Bootstrapping)\n",
    "- Input realistic market data format: T-bills (simple yields), notes (par yields)\n",
    "- Bootstrap discount factors $D(t)$\n",
    "- Derive zero rates $z(t)$\n",
    "- Implement interpolation layer and reusable curve object\n",
    "- Add curve QC checks: positivity, monotonicity, smoothness flags\n",
    "\n",
    "### Step 2 — Bond Pricing Engine\n",
    "- Fixed-rate semiannual coupon bonds\n",
    "- Cashflow schedule construction\n",
    "- Accrued interest and clean/dirty pricing\n",
    "- Day count support: 30/360 and ACT/365\n",
    "- Vectorized pricing for multiple bonds\n",
    "\n",
    "### Step 3 — Corporate Bond Pricing (Spread over Curve)\n",
    "- Spread-based discounting:\n",
    "$$\n",
    "D_s(t) = D(t)e^{-s\\tau(t)}\n",
    "$$\n",
    "- Pricing via spread curve / bucketed spreads\n",
    "- Explain matrix pricing intuition\n",
    "\n",
    "### Step 4 — Risk Measures\n",
    "- Macaulay duration, modified duration, convexity, DV01\n",
    "- Spread duration\n",
    "- Analytical formulas + finite difference validation checks\n",
    "\n",
    "### Step 5 — Scenario Analysis\n",
    "- Parallel shocks: $\\pm 25$bp, $\\pm 50$bp\n",
    "- Steepener / flattener twists\n",
    "- Spread widening scenarios\n",
    "- P&L tables and exposure summaries\n",
    "\n",
    "### Step 6 — Portfolio Pricing + QC\n",
    "- Price 20+ bonds simultaneously\n",
    "- Vectorized computation and caching\n",
    "- Data validation flags (invalid maturity, negative price, broken schedule, etc.)\n",
    "- Logging-style reporting\n",
    "\n",
    "### Step 7 — Interview Readiness Layer\n",
    "For each module:\n",
    "- What it does in production\n",
    "- Trade-offs and design decisions\n",
    "- Real-world complications not modeled (holidays, stubs, calls, OAS models, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "## Non-Goals (Explicit)\n",
    "This platform does not attempt full Street OAS or callable/putable modeling.\n",
    "Those require option-adjusted modeling (tree/MC/PDE) and volatility inputs.\n",
    "We will implement an OAS-style *intuition layer* via spread-over-curve discounting,\n",
    "and clearly label what is simplified vs institutional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da3b4d-0649-474b-acd3-3f3d02c66b91",
   "metadata": {},
   "source": [
    "# **I. Yield Curve Construction (Bootstrapping)**\n",
    "\n",
    "## Goal\n",
    "Bootstrap a risk-free discount curve from:\n",
    "- Treasury bills (money-market simple yields)\n",
    "- Treasury notes (par yields, semiannual coupons)\n",
    "\n",
    "We will:\n",
    "1. Bootstrap discount factors $D(t)$ at instrument maturities (\"knots\")\n",
    "2. Interpolate $\\log D(t)$ between knots\n",
    "3. Derive zero rates $z(t)$ as needed\n",
    "4. Wrap results in a reusable curve object with QC checks\n",
    "\n",
    "---\n",
    "\n",
    "## Conventions (Default)\n",
    "- Bills: ACT/360 for money-market year fraction in $D(T)=\\frac{1}{1+y\\tau}$\n",
    "- Notes: 30/360 for coupon accrual fractions\n",
    "- Curve time for continuous zeros: ACT/365\n",
    "- Interpolation: linear interpolation on $\\log D(t)$\n",
    "\n",
    "---\n",
    "\n",
    "## Bootstrapping Theory (The Math)\n",
    "\n",
    "### Bills (simple yield)\n",
    "Given quote $y$ and year fraction $\\tau$:\n",
    "$$\n",
    "D(T)=\\frac{1}{1+y\\tau}\n",
    "$$\n",
    "\n",
    "### Notes (par yields)\n",
    "For maturity $t_n$, par yield $c$, frequency $m=2$, coupon $\\frac{c}{m}$:\n",
    "$$\n",
    "1=\\sum_{i=1}^{n}\\frac{c}{m}D(t_i)+D(t_n)\n",
    "$$\n",
    "\n",
    "Solve for $D(t_n)$:\n",
    "$$\n",
    "D(t_n)=\\frac{1-\\sum_{i=1}^{n-1}\\frac{c}{m}D(t_i)}{1+\\frac{c}{m}}\n",
    "$$\n",
    "\n",
    "We will compute $D(t_i)$ for intermediate coupon dates using interpolation on $\\log D(t)$ from already-bootstrapped knots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2885625-a8b7-44e8-9699-375e5f96fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Iterable\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce7e6fa-db9e-47fb-8211-58bad8028f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day count utilities\n",
    "\n",
    "def yearfrac(start: pd.Timestamp, end: pd.Timestamp, convention: str) -> float:\n",
    "    \"\"\"\n",
    "    Year fraction between two dates under a day count convention.\n",
    "\n",
    "    Supported:\n",
    "    - ACT/365, ACT/365F\n",
    "    - ACT/360\n",
    "    - 30/360, 30/360US (US bond basis)\n",
    "    \"\"\"\n",
    "    convention = convention.upper().replace(\" \", \"\")\n",
    "    if end < start:\n",
    "        raise ValueError(f\"end < start: {start=} {end=}\")\n",
    "\n",
    "    if convention in (\"ACT/365\", \"ACT/365F\"):\n",
    "        return (end - start).days / 365.0\n",
    "\n",
    "    if convention == \"ACT/360\":\n",
    "        return (end - start).days / 360.0\n",
    "\n",
    "    if convention in (\"30/360\", \"30/360US\"):\n",
    "        y1, m1, d1 = start.year, start.month, start.day\n",
    "        y2, m2, d2 = end.year, end.month, end.day\n",
    "\n",
    "        # 30/360 US convention\n",
    "        if d1 == 31:\n",
    "            d1 = 30\n",
    "        if d2 == 31 and d1 == 30:\n",
    "            d2 = 30\n",
    "\n",
    "        return ((y2 - y1) * 360 + (m2 - m1) * 30 + (d2 - d1)) / 360.0\n",
    "\n",
    "    raise ValueError(f\"Unsupported day count convention: {convention}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de0271f-63c3-49fc-8944-71b2d14fa28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule generation\n",
    "\n",
    "def semiannual_coupon_dates(val_date: pd.Timestamp, maturity: pd.Timestamp) -> List[pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Generate semiannual coupon payment dates strictly AFTER val_date, ending at maturity.\n",
    "\n",
    "    This avoids accidentally including a coupon date that is only a couple days after val_date\n",
    "    due to naive backward stepping.\n",
    "    \"\"\"\n",
    "    val_date = pd.Timestamp(val_date)\n",
    "    maturity = pd.Timestamp(maturity)\n",
    "\n",
    "    if maturity <= val_date:\n",
    "        raise ValueError(\"Maturity must be after valuation date.\")\n",
    "\n",
    "    # Step backward in 6M increments to find the last coupon date <= val_date\n",
    "    d = maturity\n",
    "    while d > val_date:\n",
    "        d = d - pd.DateOffset(months=6)\n",
    "\n",
    "    prev_coupon = d  # <= val_date\n",
    "    next_coupon = prev_coupon + pd.DateOffset(months=6)\n",
    "\n",
    "    # Build forward schedule from next_coupon to maturity\n",
    "    dates = []\n",
    "    d = next_coupon\n",
    "    while d < maturity:\n",
    "        dates.append(d)\n",
    "        d = d + pd.DateOffset(months=6)\n",
    "\n",
    "    dates.append(maturity)\n",
    "    # Ensure strictly greater than val_date\n",
    "    dates = [x for x in dates if x > val_date]\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a53e9271-5600-486f-a578-d2ef0b914359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve object (interpolation on log DF)\n",
    "## vectorized DF queries + caching.\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ZeroCurve:\n",
    "    \"\"\"\n",
    "    Discount curve represented by bootstrapped knot discount factors,\n",
    "    interpolated linearly in log discount factor space.\n",
    "    \"\"\"\n",
    "    val_date: pd.Timestamp\n",
    "    knot_dates: np.ndarray          # dtype datetime64[ns]\n",
    "    knot_log_dfs: np.ndarray        # log(D)\n",
    "    zero_day_count: str = \"ACT/365\"\n",
    "\n",
    "    def _to_datetime64(self, dates: Iterable[pd.Timestamp]) -> np.ndarray:\n",
    "        return np.array([pd.Timestamp(d).to_datetime64() for d in dates], dtype=\"datetime64[ns]\")\n",
    "\n",
    "    def df(self, dates: Iterable[pd.Timestamp]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Vectorized discount factor lookup with log-linear interpolation.\n",
    "        Short-end extrapolation (between val_date and first knot) uses flat\n",
    "        continuously-compounded zero rate implied by the first knot.\n",
    "        \"\"\"\n",
    "        dates_list = [pd.Timestamp(d) for d in dates]\n",
    "        x = self._to_datetime64(dates_list).astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "        kx = self.knot_dates.astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "        kv = self.knot_log_dfs\n",
    "    \n",
    "        x_min, x_max = x.min(), x.max()\n",
    "        k_min, k_max = kx.min(), kx.max()\n",
    "    \n",
    "        if x_max > k_max:\n",
    "            raise ValueError(\"Requested date beyond curve knot range (no long-end extrapolation).\")\n",
    "    \n",
    "        # Precompute first-knot flat cc zero for short-end extrapolation\n",
    "        first_date = pd.Timestamp(pd.to_datetime(self.knot_dates[0]))\n",
    "        df1 = float(np.exp(kv[0]))\n",
    "        tau1 = yearfrac(self.val_date, first_date, self.zero_day_count)\n",
    "        if tau1 <= 0:\n",
    "            raise ValueError(\"First knot must be after valuation date.\")\n",
    "        z1 = -np.log(df1) / tau1\n",
    "    \n",
    "        out = np.empty_like(x, dtype=float)\n",
    "    \n",
    "        # Short-end: x < first knot => D(t)=exp(-z1*tau(t))\n",
    "        mask_short = x < k_min\n",
    "        if np.any(mask_short):\n",
    "            taus = np.array([yearfrac(self.val_date, dates_list[i], self.zero_day_count)\n",
    "                             for i in np.where(mask_short)[0]], dtype=float)\n",
    "            if np.any(taus < 0):\n",
    "                raise ValueError(\"Requested date before valuation date.\")\n",
    "            out[mask_short] = np.exp(-z1 * taus)\n",
    "    \n",
    "        # Within knots: log-linear interpolation\n",
    "        mask_in = ~mask_short\n",
    "        if np.any(mask_in):\n",
    "            log_df = np.interp(x[mask_in], kx, kv)\n",
    "            out[mask_in] = np.exp(log_df)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def zero_rate_cc(self, dates: Iterable[pd.Timestamp]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Continuously compounded zero rate z(t) implied by D(t)=exp(-z*tau).\n",
    "        tau uses zero_day_count (default ACT/365).\n",
    "        \"\"\"\n",
    "        dates_list = [pd.Timestamp(d) for d in dates]\n",
    "        dfs = self.df(dates_list)\n",
    "\n",
    "        taus = np.array([yearfrac(self.val_date, d, self.zero_day_count) for d in dates_list], dtype=float)\n",
    "        if np.any(taus <= 0):\n",
    "            raise ValueError(\"Non-positive tau encountered in zero rate computation.\")\n",
    "\n",
    "        return -np.log(dfs) / taus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634cad03-a08a-4f99-beb3-7732a8aae2de",
   "metadata": {},
   "source": [
    "## Market Data Schema\n",
    "\n",
    "We represent market instruments in a DataFrame with realistic fields:\n",
    "\n",
    "### Bills\n",
    "- type = \"bill\"\n",
    "- maturity (date)\n",
    "- quote = simple yield (annualized)\n",
    "- day_count = \"ACT/360\" (market)\n",
    "\n",
    "### Notes\n",
    "- type = \"note\"\n",
    "- maturity (date)\n",
    "- quote = par yield (annualized)\n",
    "- coupon_freq = 2\n",
    "- day_count = \"30/360\" (bond basis)\n",
    "\n",
    "We bootstrap discount factors in maturity order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa711ba-0c73-4e93-938d-ce35b3d768bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>maturity</th>\n",
       "      <th>quote</th>\n",
       "      <th>day_count</th>\n",
       "      <th>coupon_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bill</td>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>ACT/360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bill</td>\n",
       "      <td>2026-03-13</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>ACT/360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bill</td>\n",
       "      <td>2026-05-15</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>ACT/360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bill</td>\n",
       "      <td>2026-08-14</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>ACT/360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill</td>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>ACT/360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>note</td>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>30/360</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>note</td>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>30/360</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>note</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>30/360</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type   maturity   quote day_count  coupon_freq\n",
       "0  bill 2026-02-20  0.0525   ACT/360          NaN\n",
       "1  bill 2026-03-13  0.0520   ACT/360          NaN\n",
       "2  bill 2026-05-15  0.0515   ACT/360          NaN\n",
       "3  bill 2026-08-14  0.0505   ACT/360          NaN\n",
       "4  bill 2027-02-12  0.0485   ACT/360          NaN\n",
       "5  note 2028-02-15  0.0450    30/360          2.0\n",
       "6  note 2031-02-15  0.0430    30/360          2.0\n",
       "7  note 2036-02-15  0.0425    30/360          2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example market data (simulated but realistic structure)\n",
    "\n",
    "val_date = pd.Timestamp(\"2026-02-13\")\n",
    "\n",
    "market = pd.DataFrame([\n",
    "    {\"type\": \"bill\", \"maturity\": pd.Timestamp(\"2026-03-13\"), \"quote\": 0.0520, \"day_count\": \"ACT/360\"},\n",
    "    {\"type\": \"bill\", \"maturity\": pd.Timestamp(\"2026-05-15\"), \"quote\": 0.0515, \"day_count\": \"ACT/360\"},\n",
    "    {\"type\": \"bill\", \"maturity\": pd.Timestamp(\"2026-08-14\"), \"quote\": 0.0505, \"day_count\": \"ACT/360\"},\n",
    "    {\"type\": \"bill\", \"maturity\": pd.Timestamp(\"2027-02-12\"), \"quote\": 0.0485, \"day_count\": \"ACT/360\"},\n",
    "    {\"type\": \"bill\", \"maturity\": pd.Timestamp(\"2026-02-20\"), \"quote\": 0.0525, \"day_count\": \"ACT/360\"},\n",
    "    {\"type\": \"note\", \"maturity\": pd.Timestamp(\"2028-02-15\"), \"quote\": 0.0450, \"coupon_freq\": 2, \"day_count\": \"30/360\"},\n",
    "    {\"type\": \"note\", \"maturity\": pd.Timestamp(\"2031-02-15\"), \"quote\": 0.0430, \"coupon_freq\": 2, \"day_count\": \"30/360\"},\n",
    "    {\"type\": \"note\", \"maturity\": pd.Timestamp(\"2036-02-15\"), \"quote\": 0.0425, \"coupon_freq\": 2, \"day_count\": \"30/360\"},\n",
    "])\n",
    "\n",
    "market = market.sort_values(\"maturity\").reset_index(drop=True)\n",
    "market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc46443-c2d3-4974-a2ba-99a7167a52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping engine (bootstrap knots, update curve, proceed)\n",
    "\n",
    "def bootstrap_curve_from_bills_notes(\n",
    "    market: pd.DataFrame,\n",
    "    val_date: pd.Timestamp,\n",
    "    zero_day_count: str = \"ACT/365\",\n",
    "    enforce_monotone_df: bool = True,\n",
    ") -> ZeroCurve:\n",
    "\n",
    "    market = market.sort_values(\"maturity\").reset_index(drop=True)\n",
    "\n",
    "    # Maintain knots as dict: {date: logDF}\n",
    "    knot_logdf: dict[pd.Timestamp, float] = {}\n",
    "\n",
    "    def _sorted_knots():\n",
    "        dates = sorted(knot_logdf.keys())\n",
    "        logdfs = np.array([knot_logdf[d] for d in dates], dtype=float)\n",
    "        kx = np.array(\n",
    "            [d.to_datetime64().astype(\"datetime64[ns]\").astype(\"int64\") for d in dates],\n",
    "            dtype=np.int64,\n",
    "        )\n",
    "        return dates, logdfs, kx\n",
    "\n",
    "    def current_curve() -> Optional[ZeroCurve]:\n",
    "        dates, logdfs, _ = _sorted_knots()\n",
    "        if len(dates) < 2:\n",
    "            return None\n",
    "        kd = np.array([d.to_datetime64() for d in dates], dtype=\"datetime64[ns]\")\n",
    "        return ZeroCurve(val_date, kd, logdfs, zero_day_count)\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP A: Bills\n",
    "    # =====================================================\n",
    "    for _, row in market[market[\"type\"] == \"bill\"].iterrows():\n",
    "        T = pd.Timestamp(row[\"maturity\"])\n",
    "        y = float(row[\"quote\"])\n",
    "        dc = str(row.get(\"day_count\", \"ACT/360\"))\n",
    "\n",
    "        tau = yearfrac(val_date, T, dc)\n",
    "        if tau <= 0:\n",
    "            raise ValueError(\"Bill maturity must be after valuation date.\")\n",
    "\n",
    "        df_T = 1.0 / (1.0 + y * tau)\n",
    "        if not (0.0 < df_T < 1.5):\n",
    "            raise ValueError(\"Bill DF out of bounds.\")\n",
    "\n",
    "        knot_logdf[T] = float(np.log(df_T))\n",
    "\n",
    "        if enforce_monotone_df:\n",
    "            dates, logdfs, _ = _sorted_knots()\n",
    "            if np.any(np.diff(np.exp(logdfs)) > 1e-10):\n",
    "                raise ValueError(\"Non-monotone DF detected in bills.\")\n",
    "\n",
    "    if len(knot_logdf) < 2:\n",
    "        raise ValueError(\"Need at least two bills before notes.\")\n",
    "\n",
    "    # =====================================================\n",
    "    # STEP B: Notes (root solve)\n",
    "    # =====================================================\n",
    "    for _, row in market[market[\"type\"] == \"note\"].iterrows():\n",
    "\n",
    "        T = pd.Timestamp(row[\"maturity\"])\n",
    "        c = float(row[\"quote\"])\n",
    "        freq = int(row.get(\"coupon_freq\", 2))\n",
    "        if freq != 2:\n",
    "            raise NotImplementedError(\"Only semiannual supported.\")\n",
    "\n",
    "        curve = current_curve()\n",
    "        if curve is None:\n",
    "            raise ValueError(\"Curve not initialized.\")\n",
    "\n",
    "        cpn_dates = semiannual_coupon_dates(val_date, T)\n",
    "        coupon = c / freq\n",
    "\n",
    "        dates, logdfs, kx = _sorted_knots()\n",
    "        kv = logdfs\n",
    "\n",
    "        tL = dates[-1]\n",
    "        if tL >= T:\n",
    "            raise ValueError(\"Note maturity must exceed last knot.\")\n",
    "\n",
    "        logDF_L = knot_logdf[tL]\n",
    "\n",
    "        tL_int = tL.to_datetime64().astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "        T_int = T.to_datetime64().astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "\n",
    "        def df_with_unknown_endpoint(date: pd.Timestamp, logDF_T: float) -> float:\n",
    "\n",
    "            x = date.to_datetime64().astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "\n",
    "            # -------------------------\n",
    "            # Case 1: short-end extrapolation\n",
    "            # -------------------------\n",
    "            if x < kx.min():\n",
    "                first_date = dates[0]\n",
    "                first_logdf = kv[0]\n",
    "                df1 = float(np.exp(first_logdf))\n",
    "\n",
    "                tau1 = yearfrac(val_date, first_date, zero_day_count)\n",
    "                z1 = -np.log(df1) / tau1\n",
    "\n",
    "                tau_x = yearfrac(val_date, date, zero_day_count)\n",
    "                return float(np.exp(-z1 * tau_x))\n",
    "\n",
    "            # -------------------------\n",
    "            # Case 2: within known knots\n",
    "            # -------------------------\n",
    "            if x <= tL_int:\n",
    "                logDF = float(np.interp(x, kx, kv))\n",
    "                return float(np.exp(logDF))\n",
    "\n",
    "            # -------------------------\n",
    "            # Case 3: between (tL, T]\n",
    "            # -------------------------\n",
    "            if x <= T_int:\n",
    "                w = (x - tL_int) / (T_int - tL_int)\n",
    "                logDF = (1 - w) * logDF_L + w * logDF_T\n",
    "                return float(np.exp(logDF))\n",
    "\n",
    "            raise ValueError(\"Date beyond maturity during bootstrap.\")\n",
    "\n",
    "        def par_residual(logDF_T: float) -> float:\n",
    "            pv = 0.0\n",
    "            for d in cpn_dates:\n",
    "                pv += coupon * df_with_unknown_endpoint(d, logDF_T)\n",
    "            pv += df_with_unknown_endpoint(T, logDF_T)\n",
    "            return pv - 1.0\n",
    "\n",
    "        # Solve\n",
    "        a = np.log(1e-6)\n",
    "        b = min(logDF_L, -1e-12)\n",
    "\n",
    "        fa, fb = par_residual(a), par_residual(b)\n",
    "        if fa * fb > 0:\n",
    "            raise ValueError(\"Root not bracketed — inconsistent market data.\")\n",
    "\n",
    "        logDF_T = brentq(par_residual, a, b, maxiter=300, xtol=1e-14)\n",
    "\n",
    "        knot_logdf[T] = float(logDF_T)\n",
    "\n",
    "        if enforce_monotone_df:\n",
    "            dates2, logdfs2, _ = _sorted_knots()\n",
    "            if np.any(np.diff(np.exp(logdfs2)) > 1e-10):\n",
    "                raise ValueError(\"Non-monotone DF after adding note.\")\n",
    "\n",
    "    # =====================================================\n",
    "    # Final curve\n",
    "    # =====================================================\n",
    "    final_dates, final_logdfs, _ = _sorted_knots()\n",
    "    kd = np.array([d.to_datetime64() for d in final_dates], dtype=\"datetime64[ns]\")\n",
    "\n",
    "    return ZeroCurve(val_date, kd, final_logdfs, zero_day_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b0c1a13-ac01-4231-9f3d-45032c142935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC diagnostics\n",
    "\n",
    "def curve_qc_report(curve: ZeroCurve) -> pd.DataFrame:\n",
    "    dates = pd.to_datetime(curve.knot_dates)\n",
    "    dfs = np.exp(curve.knot_log_dfs)\n",
    "\n",
    "    taus = np.array([\n",
    "        yearfrac(curve.val_date, pd.Timestamp(d), curve.zero_day_count)\n",
    "        for d in dates\n",
    "    ])\n",
    "\n",
    "    zeros = -np.log(dfs) / taus\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"date\": dates,\n",
    "        \"tau\": taus,\n",
    "        \"df\": dfs,\n",
    "        \"zero_cc\": zeros,\n",
    "        \"df_positive\": dfs > 0,\n",
    "        \"df_monotone\": np.r_[True, np.diff(dfs) <= 1e-10],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3d8b927-efe1-41fe-82e8-455c1fb611af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   knot_date        df\n",
      "0 2026-02-20  0.998980\n",
      "1 2026-03-13  0.995972\n",
      "2 2026-05-15  0.987149\n",
      "3 2026-08-14  0.975105\n",
      "4 2027-02-12  0.953254\n",
      "5 2028-02-15  0.893272\n",
      "6 2031-02-15  0.790633\n",
      "7 2036-02-15  0.642857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>df</th>\n",
       "      <th>zero_cc</th>\n",
       "      <th>df_positive</th>\n",
       "      <th>df_monotone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-03-13</td>\n",
       "      <td>0.076712</td>\n",
       "      <td>0.995972</td>\n",
       "      <td>0.052616</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-05-15</td>\n",
       "      <td>0.249315</td>\n",
       "      <td>0.987149</td>\n",
       "      <td>0.051878</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-08-14</td>\n",
       "      <td>0.498630</td>\n",
       "      <td>0.975105</td>\n",
       "      <td>0.050559</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.953254</td>\n",
       "      <td>0.048006</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>2.005479</td>\n",
       "      <td>0.893272</td>\n",
       "      <td>0.056278</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>5.008219</td>\n",
       "      <td>0.790633</td>\n",
       "      <td>0.046907</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>10.010959</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        tau        df   zero_cc  df_positive  df_monotone\n",
       "0 2026-02-20   0.019178  0.998980  0.053202         True         True\n",
       "1 2026-03-13   0.076712  0.995972  0.052616         True         True\n",
       "2 2026-05-15   0.249315  0.987149  0.051878         True         True\n",
       "3 2026-08-14   0.498630  0.975105  0.050559         True         True\n",
       "4 2027-02-12   0.997260  0.953254  0.048006         True         True\n",
       "5 2028-02-15   2.005479  0.893272  0.056278         True         True\n",
       "6 2031-02-15   5.008219  0.790633  0.046907         True         True\n",
       "7 2036-02-15  10.010959  0.642857  0.044135         True         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tau</th>\n",
       "      <th>df</th>\n",
       "      <th>zero_cc</th>\n",
       "      <th>df_positive</th>\n",
       "      <th>df_monotone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-03-13</td>\n",
       "      <td>0.076712</td>\n",
       "      <td>0.995972</td>\n",
       "      <td>0.052616</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-05-15</td>\n",
       "      <td>0.249315</td>\n",
       "      <td>0.987149</td>\n",
       "      <td>0.051878</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-08-14</td>\n",
       "      <td>0.498630</td>\n",
       "      <td>0.975105</td>\n",
       "      <td>0.050559</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.953254</td>\n",
       "      <td>0.048006</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>2.005479</td>\n",
       "      <td>0.893272</td>\n",
       "      <td>0.056278</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>5.008219</td>\n",
       "      <td>0.790633</td>\n",
       "      <td>0.046907</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>10.010959</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        tau        df   zero_cc  df_positive  df_monotone\n",
       "0 2026-02-20   0.019178  0.998980  0.053202         True         True\n",
       "1 2026-03-13   0.076712  0.995972  0.052616         True         True\n",
       "2 2026-05-15   0.249315  0.987149  0.051878         True         True\n",
       "3 2026-08-14   0.498630  0.975105  0.050559         True         True\n",
       "4 2027-02-12   0.997260  0.953254  0.048006         True         True\n",
       "5 2028-02-15   2.005479  0.893272  0.056278         True         True\n",
       "6 2031-02-15   5.008219  0.790633  0.046907         True         True\n",
       "7 2036-02-15  10.010959  0.642857  0.044135         True         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build curve + inspect knots\n",
    "\n",
    "curve = bootstrap_curve_from_bills_notes(market, val_date)\n",
    "\n",
    "knot_df = pd.DataFrame({\n",
    "    \"knot_date\": pd.to_datetime(curve.knot_dates),\n",
    "    \"df\": np.exp(curve.knot_log_dfs),\n",
    "})\n",
    "print(knot_df)\n",
    "\n",
    "qc = curve_qc_report(curve)\n",
    "display(qc.head(10))\n",
    "display(qc.tail(10))\n",
    "\n",
    "assert (np.exp(curve.knot_log_dfs) > 0).all()\n",
    "assert (np.diff(np.exp(curve.knot_log_dfs)) <= 1e-10).all(), \"DF not monotone decreasing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec964ead-1b3b-4984-a8a5-aec03c3b52d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2026-02-15 00:00:00'), Timestamp('2026-08-15 00:00:00'), Timestamp('2027-02-15 00:00:00'), Timestamp('2027-08-15 00:00:00'), Timestamp('2028-02-15 00:00:00')]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Repricing the 2028 note using the curve and verifing it prices to par.\n",
    "\n",
    "def price_par_note_check(curve, maturity, par_yield):\n",
    "    freq = 2\n",
    "    coupon = par_yield / freq\n",
    "    cpn_dates = semiannual_coupon_dates(val_date, maturity)\n",
    "\n",
    "    pv = 0.0\n",
    "    for d in cpn_dates:\n",
    "        pv += coupon * curve.df([d])[0]\n",
    "    pv += curve.df([maturity])[0]\n",
    "\n",
    "    return pv\n",
    "\n",
    "print(semiannual_coupon_dates(val_date, pd.Timestamp(\"2028-02-15\")))\n",
    "print(price_par_note_check(curve, pd.Timestamp(\"2028-02-15\"), 0.0450))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c87152-cf53-4143-b359-0a9a20703aa7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Yield Curve Boostrapping Results: Bootstrapped Risk-Free Curve (Bills + Notes)\n",
    "\n",
    "We successfully constructed a reusable discount curve from:\n",
    "- Treasury bills quoted as simple yields (ACT/360)\n",
    "- Treasury notes quoted as par yields (semiannual coupons)\n",
    "\n",
    "### Key design decisions\n",
    "- Curve representation: discount factors $D(t)$ at bootstrapped knot maturities.\n",
    "- Interpolation: linear in $\\log D(t)$ to ensure $D(t) > 0$ and stabilize numerical behavior.\n",
    "- Short-end extrapolation (between valuation date and first knot): flat continuously-compounded zero rate implied by the first knot:\n",
    "$$\n",
    "z_1 = -\\frac{\\ln D(t_1)}{\\tau(t_1)}, \\quad D(t)=e^{-z_1 \\tau(t)} \\;\\; \\text{for} \\;\\; t \\le t_1.\n",
    "$$\n",
    "- Notes are calibrated by solving for $\\log D(T)$ via root-finding so that par pricing holds.\n",
    "\n",
    "### Internal consistency check\n",
    "Repricing the 2Y par note using the bootstrapped curve returned $PV \\approx 1.0$, confirming that the curve calibration and curve discounting logic are consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8287dd-3a3e-4ca1-baea-89f54d79028e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **II. Bond Pricing Engine (Accrued Interest, Settlement)**\n",
    "\n",
    "## Goal\n",
    "Implement a production-style fixed-rate bond pricing engine that:\n",
    "- Constructs coupon cashflows from a schedule\n",
    "- Discounts cashflows using the bootstrapped curve $D(t)$\n",
    "- Computes accrued interest using market day-count conventions\n",
    "- Returns dirty and clean prices\n",
    "- Supports semiannual coupon bonds (baseline IG convention)\n",
    "- Provides a vectorized pathway for portfolio pricing\n",
    "\n",
    "---\n",
    "\n",
    "## Core Definitions\n",
    "\n",
    "### Settlement vs Valuation Date\n",
    "- **Valuation date** $t_0$: the market snapshot date (curve build date).\n",
    "- **Settlement date** $t_{set}$: the date the bond trade settles (typically $t_0 + 2$ business days for corporates; simplified as $t_0 + 2$ calendar days for now).\n",
    "\n",
    "Pricing and accrued interest are computed as of $t_{set}$.\n",
    "\n",
    "---\n",
    "\n",
    "## Cashflows\n",
    "\n",
    "For a bond with face $N$, annual coupon rate $c$, coupon frequency $m$ (semiannual: $m=2$),\n",
    "coupon payment dates $t_1,\\dots,t_n$ after settlement:\n",
    "\n",
    "Coupon cashflow at date $t_i$:\n",
    "- Simplified regular schedule (baseline): $CF^{coupon}_i = N \\cdot \\frac{c}{m}$\n",
    "- More general (to be used for irregular/stub periods): $CF^{coupon}_i = N \\cdot c \\cdot \\alpha_i$ where $\\alpha_i$ is the accrual fraction.\n",
    "\n",
    "Principal at maturity $T$:\n",
    "$$\n",
    "CF^{principal}(T) = N\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Discounting (Dirty Price)\n",
    "\n",
    "Dirty price (per 100 notional) at settlement:\n",
    "$$\n",
    "P_{dirty} = \\frac{100}{N}\\sum_{i=1}^{n} CF_i \\cdot D(t_i)\n",
    "$$\n",
    "\n",
    "We use the curve’s discount factor function $D(t)$ with the curve’s interpolation/extrapolation policy.\n",
    "\n",
    "---\n",
    "\n",
    "## Accrued Interest\n",
    "\n",
    "Accrued interest at settlement depends on day count convention (e.g., 30/360, ACT/365).\n",
    "\n",
    "Let:\n",
    "- $t_{prev}$ = previous coupon date (on or before settlement)\n",
    "- $t_{next}$ = next coupon date (after settlement)\n",
    "\n",
    "For regular coupon schedules:\n",
    "$$\n",
    "AI = N \\cdot \\frac{c}{m}\\cdot \\frac{\\text{yearfrac}(t_{prev}, t_{set})}{\\text{yearfrac}(t_{prev}, t_{next})}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Clean Price\n",
    "\n",
    "Clean price is the quoted market price:\n",
    "$$\n",
    "P_{clean} = P_{dirty} - \\frac{100}{N}AI\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## QC / Validation Checks (Production Mindset)\n",
    "Before pricing we validate:\n",
    "- $t_{set} < T$ (not matured)\n",
    "- coupon frequency is supported\n",
    "- coupon rate is reasonable ($c \\ge 0$ typically for IG)\n",
    "- schedule dates are strictly increasing\n",
    "- day count convention recognized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc667a86-58ff-4327-a1fe-1e9417af6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Helpers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Iterable, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87d1d887-7a22-4402-adf9-1bcd5f5d7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settlement convention (T+2 baseline)\n",
    "\n",
    "def settlement_date(val_date: pd.Timestamp, lag_days: int = 2) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Simplified settlement date: valuation date + lag_days (calendar days).\n",
    "    In production: use business-day calendars + holiday schedules.\n",
    "    \"\"\"\n",
    "    return pd.Timestamp(val_date) + pd.Timedelta(days=lag_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bea6d89e-6e62-4178-a302-14ca5ea80ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coupon date utilities (previous/next coupon)\n",
    "\n",
    "def previous_coupon_date(settle: pd.Timestamp, maturity: pd.Timestamp, freq: int = 2) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Find the most recent coupon date on or before settlement, using a schedule\n",
    "    anchored at maturity and stepping backward by 12/freq months.\n",
    "\n",
    "    This is a pragmatic approximation when issue date is unknown.\n",
    "    \"\"\"\n",
    "    if freq <= 0:\n",
    "        raise ValueError(\"freq must be positive\")\n",
    "    months = int(12 / freq)\n",
    "\n",
    "    d = pd.Timestamp(maturity)\n",
    "    settle = pd.Timestamp(settle)\n",
    "\n",
    "    # Step backwards until d <= settle\n",
    "    while d > settle:\n",
    "        d = d - pd.DateOffset(months=months)\n",
    "    return d\n",
    "\n",
    "def next_coupon_date(settle: pd.Timestamp, maturity: pd.Timestamp, freq: int = 2) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Next coupon date strictly after settlement.\n",
    "    \"\"\"\n",
    "    prev = previous_coupon_date(settle, maturity, freq)\n",
    "    months = int(12 / freq)\n",
    "    nxt = prev + pd.DateOffset(months=months)\n",
    "    return nxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c258fb00-1d8d-4a7b-a3ac-befd28c5555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cashflow schedule after settlement\n",
    "\n",
    "def coupon_schedule_after_settlement(\n",
    "    settle: pd.Timestamp,\n",
    "    maturity: pd.Timestamp,\n",
    "    freq: int = 2,\n",
    ") -> List[pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    All coupon payment dates strictly after settlement, ending at maturity.\n",
    "    \"\"\"\n",
    "    if settle >= maturity:\n",
    "        return []\n",
    "\n",
    "    months = int(12 / freq)\n",
    "    d = next_coupon_date(settle, maturity, freq)\n",
    "\n",
    "    dates = []\n",
    "    while d < maturity:\n",
    "        dates.append(d)\n",
    "        d = d + pd.DateOffset(months=months)\n",
    "\n",
    "    dates.append(pd.Timestamp(maturity))\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f52c8de-54f8-42f4-96e0-a4dc472a6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accrued interest\n",
    "\n",
    "def accrued_interest(\n",
    "    settle: pd.Timestamp,\n",
    "    maturity: pd.Timestamp,\n",
    "    coupon_rate: float,\n",
    "    face: float,\n",
    "    freq: int,\n",
    "    day_count: str,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Accrued interest amount in currency units (not per 100).\n",
    "    \"\"\"\n",
    "    if settle >= maturity:\n",
    "        return 0.0\n",
    "\n",
    "    t_prev = previous_coupon_date(settle, maturity, freq)\n",
    "    t_next = next_coupon_date(settle, maturity, freq)\n",
    "\n",
    "    # Accrued fraction of the coupon period\n",
    "    accrual_num = yearfrac(t_prev, settle, day_count)\n",
    "    accrual_den = yearfrac(t_prev, t_next, day_count)\n",
    "\n",
    "    if accrual_den <= 0:\n",
    "        raise ValueError(\"Invalid coupon period length from schedule/daycount.\")\n",
    "\n",
    "    coupon_per_period = face * (coupon_rate / freq)\n",
    "    return coupon_per_period * (accrual_num / accrual_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5057768-1043-4d83-934a-6f616e5ff967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bond definition\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Bond:\n",
    "    bond_id: str\n",
    "    maturity: pd.Timestamp\n",
    "    coupon_rate: float          # annual coupon rate, e.g. 0.05 for 5%\n",
    "    freq: int = 2               # semiannual default\n",
    "    day_count: str = \"30/360\"   # typical for corporates\n",
    "    face: float = 100.0         # notional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a9f6fc3-213b-4d2f-b89d-bc2f541dc74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing: dirty and clean\n",
    "\n",
    "def price_bond_dirty_clean(\n",
    "    curve: ZeroCurve,\n",
    "    bond: Bond,\n",
    "    val_date: pd.Timestamp,\n",
    "    settle: Optional[pd.Timestamp] = None,\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Returns (dirty_price_per_100, clean_price_per_100, accrued_interest_per_100).\n",
    "\n",
    "    Dirty = PV of remaining cashflows / face * 100\n",
    "    Clean = Dirty - Accrued\n",
    "    \"\"\"\n",
    "    if settle is None:\n",
    "        settle = settlement_date(val_date, lag_days=2)\n",
    "\n",
    "    settle = pd.Timestamp(settle)\n",
    "    maturity = pd.Timestamp(bond.maturity)\n",
    "\n",
    "    if settle >= maturity:\n",
    "        raise ValueError(f\"Bond {bond.bond_id} is matured or settles on/after maturity.\")\n",
    "\n",
    "    if bond.freq not in (1, 2, 4):\n",
    "        raise NotImplementedError(\"Supported frequencies: 1, 2, 4 (for now).\")\n",
    "\n",
    "    if bond.coupon_rate < -0.01:\n",
    "        raise ValueError(\"Suspiciously negative coupon rate.\")\n",
    "\n",
    "    # Cashflow dates after settlement\n",
    "    pay_dates = coupon_schedule_after_settlement(settle, maturity, bond.freq)\n",
    "    if len(pay_dates) == 0:\n",
    "        raise ValueError(\"No remaining cashflows after settlement; check schedule logic.\")\n",
    "\n",
    "    # Coupon CF (regular schedule assumption)\n",
    "    coupon_cf = bond.face * (bond.coupon_rate / bond.freq)\n",
    "\n",
    "    # Build cashflows vector\n",
    "    cfs = np.full(len(pay_dates), coupon_cf, dtype=float)\n",
    "    cfs[-1] += bond.face  # principal at maturity\n",
    "\n",
    "    # Discount factors for payment dates\n",
    "    dfs_pay = curve.df(pay_dates)\n",
    "    df_settle = float(curve.df([settle])[0])\n",
    "    \n",
    "    # settlement-adjusted discount factors: D_s(T)=D(T)/D(s)\n",
    "    dfs_settle_adj = dfs_pay / df_settle\n",
    "    \n",
    "    pv = float(np.sum(cfs * dfs_settle_adj))\n",
    "    dirty_per_100 = 100.0 * pv / bond.face\n",
    "\n",
    "\n",
    "    ai = accrued_interest(settle, maturity, bond.coupon_rate, bond.face, bond.freq, bond.day_count)\n",
    "    ai_per_100 = 100.0 * ai / bond.face\n",
    "\n",
    "    clean_per_100 = dirty_per_100 - ai_per_100\n",
    "\n",
    "    return dirty_per_100, clean_per_100, ai_per_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581830b-2675-4a6b-acea-7f8bf41ec26c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sanity Checks\n",
    "\n",
    "We test:\n",
    "1. Pricing returns finite values\n",
    "2. Dirty price > clean price when accrued interest > 0\n",
    "3. If settlement is very close to a coupon date, accrued interest behaves as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39e17261-4c6b-43d7-a787-95ae3f2fdef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settlement: 2026-02-15\n",
      "Dirty price: 100.93844252553204\n",
      "Accrued (per 100): 0.0\n",
      "Clean price: 100.93844252553204\n"
     ]
    }
   ],
   "source": [
    "# Demo Bond Pricing\n",
    "\n",
    "# Example bond (IG-style)\n",
    "bond = Bond(\n",
    "    bond_id=\"CORP_5Y_5PCT\",\n",
    "    maturity=pd.Timestamp(\"2031-02-15\"),\n",
    "    coupon_rate=0.05,\n",
    "    freq=2,\n",
    "    day_count=\"30/360\",\n",
    "    face=100.0,\n",
    ")\n",
    "\n",
    "val_date = pd.Timestamp(\"2026-02-13\")\n",
    "settle = settlement_date(val_date, 2)\n",
    "\n",
    "dirty, clean, ai = price_bond_dirty_clean(curve, bond, val_date, settle)\n",
    "\n",
    "print(\"Settlement:\", settle.date())\n",
    "print(\"Dirty price:\", dirty)\n",
    "print(\"Accrued (per 100):\", ai)\n",
    "print(\"Clean price:\", clean)\n",
    "\n",
    "assert np.isfinite(dirty) and np.isfinite(clean) and np.isfinite(ai)\n",
    "assert dirty >= clean - 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6dbdf2-2424-4dc2-9b14-2fa115ac5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2026-08-15 00:00:00'), Timestamp('2027-02-15 00:00:00'), Timestamp('2027-08-15 00:00:00'), Timestamp('2028-02-15 00:00:00'), Timestamp('2028-08-15 00:00:00'), Timestamp('2029-02-15 00:00:00')] ... last: 2031-02-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(coupon_schedule_after_settlement(settle, bond.maturity, bond.freq)[:6], \"...\", \"last:\", coupon_schedule_after_settlement(settle, bond.maturity, bond.freq)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577d942-3a0b-453d-be55-fbdfbc04f523",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bond Pricing Validation Layer (Why a valuation team cares)\n",
    "\n",
    "In production, most errors are not numerical - they are input and convention errors.\n",
    "We therefore add validation checks and \"reasonableness flags\" before scaling.\n",
    "\n",
    "### Checks we enforce\n",
    "- Settlement < maturity (not matured)\n",
    "- Coupon rate is within a plausible range (e.g., $0\\%$ to $20\\%$ for IG)\n",
    "- Schedule dates strictly increasing\n",
    "- Accrued interest satisfies:\n",
    "  - $0 \\le AI \\le$ coupon per period (for regular schedules)\n",
    "- Dirty price and clean price are finite\n",
    "- Dirty price $\\ge$ clean price (when $AI \\ge 0$)\n",
    "\n",
    "These checks prevent silent corruption when pricing portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fffc9fd6-4f9a-4406-8ff1-ec1eb0539605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-14 AI: 2.486111111111111 Dirty: 103.42336654570346 Clean: 100.93725543459234\n",
      "2026-02-15 AI: 0.0 Dirty: 100.93844252553204 Clean: 100.93844252553204\n",
      "2026-02-16 AI: 0.01388888888888889 Dirty: 100.95315627905092 Clean: 100.93926739016203\n"
     ]
    }
   ],
   "source": [
    "# Accrued interest should jump from ~coupon to 0 at coupon date, depending on convention.\n",
    "test_settles = [\n",
    "    pd.Timestamp(\"2026-02-14\"),\n",
    "    pd.Timestamp(\"2026-02-15\"),  # coupon date\n",
    "    pd.Timestamp(\"2026-02-16\"),\n",
    "]\n",
    "\n",
    "for s in test_settles:\n",
    "    dirty, clean, ai = price_bond_dirty_clean(curve, bond, val_date, s)\n",
    "    print(s.date(), \"AI:\", ai, \"Dirty:\", dirty, \"Clean:\", clean)\n",
    "    assert dirty >= clean - 1e-10\n",
    "    assert ai >= -1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "496eae53-3f2c-479d-aacd-7d8a10fadc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coupon period reasonableness check\n",
    "\n",
    "def qc_bond_schedule(settle: pd.Timestamp, maturity: pd.Timestamp, freq: int) -> None:\n",
    "    dates = coupon_schedule_after_settlement(settle, maturity, freq)\n",
    "    if any(dates[i] >= dates[i+1] for i in range(len(dates)-1)):\n",
    "        raise ValueError(\"Schedule is not strictly increasing.\")\n",
    "    if dates[-1] != pd.Timestamp(maturity):\n",
    "        raise ValueError(\"Schedule does not end at maturity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c847d41-8726-44f8-91b8-b51894e96161",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bond_schedule(settle, bond.maturity, bond.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75154e4b-abfe-4d33-bba7-8836fc8ce769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 30/360: 0.01388888888888889 AI ACT/365: 0.013812154696132596\n"
     ]
    }
   ],
   "source": [
    "# Compare ACT/365 vs 30/360 accrued (same bond, different daycount)\n",
    "\n",
    "bond_30360 = Bond(\"BOND_30360\", bond.maturity, bond.coupon_rate, bond.freq, \"30/360\", bond.face)\n",
    "bond_act365 = Bond(\"BOND_ACT365\", bond.maturity, bond.coupon_rate, bond.freq, \"ACT/365\", bond.face)\n",
    "\n",
    "s = pd.Timestamp(\"2026-02-16\")  # one day after coupon date\n",
    "_, _, ai_30360 = price_bond_dirty_clean(curve, bond_30360, val_date, s)\n",
    "_, _, ai_act365 = price_bond_dirty_clean(curve, bond_act365, val_date, s)\n",
    "\n",
    "print(\"AI 30/360:\", ai_30360, \"AI ACT/365:\", ai_act365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80d2c3-488c-4a66-8142-c15399050e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "022cabe3-3ffe-43e6-a373-2e79453996f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BondPricer:\n",
    "    def __init__(self, curve: ZeroCurve):\n",
    "        self.curve = curve\n",
    "\n",
    "    def validate(self, bond: Bond, settle: pd.Timestamp) -> None:\n",
    "        if settle >= bond.maturity:\n",
    "            raise ValueError(f\"{bond.bond_id}: matured at settlement.\")\n",
    "        if bond.freq not in (1, 2, 4):\n",
    "            raise NotImplementedError(\"Supported frequencies: 1, 2, 4.\")\n",
    "        if not (-0.01 <= bond.coupon_rate <= 0.25):\n",
    "            raise ValueError(f\"{bond.bond_id}: coupon out of plausible range.\")\n",
    "        # schedule monotonicity\n",
    "        dates = coupon_schedule_after_settlement(settle, bond.maturity, bond.freq)\n",
    "        if any(dates[i] >= dates[i+1] for i in range(len(dates)-1)):\n",
    "            raise ValueError(f\"{bond.bond_id}: non-increasing schedule.\")\n",
    "\n",
    "    def price(self, bond: Bond, val_date: pd.Timestamp, settle: Optional[pd.Timestamp] = None):\n",
    "        if settle is None:\n",
    "            settle = settlement_date(val_date, 2)\n",
    "\n",
    "        settle = pd.Timestamp(settle)\n",
    "        self.validate(bond, settle)\n",
    "\n",
    "        pay_dates = coupon_schedule_after_settlement(settle, bond.maturity, bond.freq)\n",
    "        coupon_cf = bond.face * (bond.coupon_rate / bond.freq)\n",
    "        cfs = np.full(len(pay_dates), coupon_cf, dtype=float)\n",
    "        cfs[-1] += bond.face\n",
    "\n",
    "        # settlement-adjusted discounting\n",
    "        dfs_pay = self.curve.df(pay_dates)\n",
    "        df_settle = float(self.curve.df([settle])[0])\n",
    "        dfs = dfs_pay / df_settle\n",
    "\n",
    "        pv = float(np.sum(cfs * dfs))\n",
    "        dirty = 100.0 * pv / bond.face\n",
    "\n",
    "        ai_amt = accrued_interest(settle, bond.maturity, bond.coupon_rate, bond.face, bond.freq, bond.day_count)\n",
    "        ai = 100.0 * ai_amt / bond.face\n",
    "\n",
    "        clean = dirty - ai\n",
    "        return dirty, clean, ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76333ee1-49ec-4e50-937b-12a4bcc9b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100.93844252553204, 100.93844252553204, 0.0)\n",
      "(100.95315627905092, 100.93926739016203, 0.01388888888888889)\n"
     ]
    }
   ],
   "source": [
    "pricer = BondPricer(curve)\n",
    "print(pricer.price(bond, val_date, pd.Timestamp(\"2026-02-15\")))\n",
    "print(pricer.price(bond, val_date, pd.Timestamp(\"2026-02-16\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd6cd4-ab00-4448-8af8-0e03588d8d9d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bond Pricing Engine Result: Time-Consistent Clean/Dirty Bond Pricer\n",
    "\n",
    "We implemented a fixed-rate bond pricing engine with:\n",
    "- Semiannual coupon schedule generation (maturity-anchored approximation)\n",
    "- Accrued interest under day-count conventions (30/360, ACT/365)\n",
    "- Dirty and clean price computation\n",
    "- Settlement-aware discounting via:\n",
    "$$\n",
    "D_s(T)=\\frac{D(T)}{D(s)}\n",
    "$$\n",
    "which ensures that prices evolve consistently when settlement date changes.\n",
    "\n",
    "### Production caveats (explicitly acknowledged)\n",
    "- Coupon schedules in production depend on issue date, first coupon date, and calendars (stubs, EOM rules).\n",
    "- Settlement is simplified as T+2 calendar days (production uses business-day calendars + holidays).\n",
    "- Curve conventions must match bond conventions; in production we share one cashflow engine for both curve calibration and bond pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6289c0-c199-421e-be38-c443fb0ff0ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **III. Portfolio Pricing (Vectorized) and Quality Control Flags**\n",
    "\n",
    "## Goal\n",
    "Price a portfolio (≥ 20 bonds) efficiently and safely:\n",
    "- Compute dirty/clean/accrued for each bond\n",
    "- Apply scenario-ready structure (we will reuse outputs for DV01 and shocks)\n",
    "- Add QC flags for invalid inputs and suspicious outputs\n",
    "\n",
    "## Why this matters in valuation teams\n",
    "Valuation groups price *millions* of instruments daily. The hard part is not pricing one bond,\n",
    "but pricing many while preventing bad inputs from corrupting downstream risk and P&L.\n",
    "\n",
    "## QC flags we add\n",
    "- `MATURED`: settlement ≥ maturity\n",
    "- `BAD_COUPON`: coupon outside plausible bounds\n",
    "- `BAD_FREQ`: unsupported frequency\n",
    "- `BAD_DATES`: schedule not increasing\n",
    "- `NEGATIVE_PRICE`: clean or dirty < 0\n",
    "- `EXTREME_PRICE`: price outside loose bounds (e.g. < 20 or > 200 per 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39fc8a12-bd70-46fc-86a9-822da9f324e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.035292</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>2032-02-15</td>\n",
       "      <td>0.050273</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count   face\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360  100.0\n",
       "1  BOND_001 2033-02-15     0.036706     2    30/360  100.0\n",
       "2  BOND_002 2033-02-15     0.035292     2    30/360  100.0\n",
       "3  BOND_003 2035-02-15     0.046705     2    30/360  100.0\n",
       "4  BOND_004 2032-02-15     0.050273     2    30/360  100.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a portfolio of 20 bonds\n",
    "\n",
    "def make_sample_portfolio(n: int = 20, seed: int = 7) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # maturities between 1Y and 10Y from val_date\n",
    "    mats = [val_date + pd.DateOffset(years=int(y)) for y in rng.integers(1, 11, size=n)]\n",
    "    mats = [pd.Timestamp(m).replace(month=2, day=15) for m in mats]  # align to Feb 15 cycle\n",
    "\n",
    "    coupons = rng.uniform(0.02, 0.08, size=n)  # 2% to 8%\n",
    "    freqs = rng.choice([2], size=n)            # semiannual baseline\n",
    "    dcs = rng.choice([\"30/360\", \"ACT/365\"], size=n, p=[0.8, 0.2])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"bond_id\": [f\"BOND_{i:03d}\" for i in range(n)],\n",
    "        \"maturity\": mats,\n",
    "        \"coupon_rate\": coupons,\n",
    "        \"freq\": freqs,\n",
    "        \"day_count\": dcs,\n",
    "        \"face\": 100.0\n",
    "    })\n",
    "    return df\n",
    "\n",
    "portfolio_df = make_sample_portfolio(20)\n",
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49c3815d-e1cd-44d0-b557-acb50793a020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>dirty</th>\n",
       "      <th>clean</th>\n",
       "      <th>accrued</th>\n",
       "      <th>flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>94.504154</td>\n",
       "      <td>94.493547</td>\n",
       "      <td>0.010606</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>94.369914</td>\n",
       "      <td>94.359718</td>\n",
       "      <td>0.010196</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.035292</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>93.539742</td>\n",
       "      <td>93.529938</td>\n",
       "      <td>0.009803</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.923368</td>\n",
       "      <td>100.910395</td>\n",
       "      <td>0.012973</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>2032-02-15</td>\n",
       "      <td>0.050273</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>101.723256</td>\n",
       "      <td>101.709291</td>\n",
       "      <td>0.013965</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOND_005</td>\n",
       "      <td>2034-02-15</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>104.870534</td>\n",
       "      <td>104.855754</td>\n",
       "      <td>0.014781</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>124.890127</td>\n",
       "      <td>124.867980</td>\n",
       "      <td>0.022147</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOND_007</td>\n",
       "      <td>2029-02-15</td>\n",
       "      <td>0.067560</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>104.305304</td>\n",
       "      <td>104.286537</td>\n",
       "      <td>0.018767</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOND_008</td>\n",
       "      <td>2027-02-15</td>\n",
       "      <td>0.057331</td>\n",
       "      <td>2</td>\n",
       "      <td>ACT/365</td>\n",
       "      <td>100.844864</td>\n",
       "      <td>100.829027</td>\n",
       "      <td>0.015837</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOND_009</td>\n",
       "      <td>2030-02-15</td>\n",
       "      <td>0.079338</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>110.717796</td>\n",
       "      <td>110.695757</td>\n",
       "      <td>0.022038</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count       dirty       clean  \\\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360   94.504154   94.493547   \n",
       "1  BOND_001 2033-02-15     0.036706     2    30/360   94.369914   94.359718   \n",
       "2  BOND_002 2033-02-15     0.035292     2    30/360   93.539742   93.529938   \n",
       "3  BOND_003 2035-02-15     0.046705     2    30/360  100.923368  100.910395   \n",
       "4  BOND_004 2032-02-15     0.050273     2    30/360  101.723256  101.709291   \n",
       "5  BOND_005 2034-02-15     0.053210     2    30/360  104.870534  104.855754   \n",
       "6  BOND_006 2035-02-15     0.079730     2    30/360  124.890127  124.867980   \n",
       "7  BOND_007 2029-02-15     0.067560     2    30/360  104.305304  104.286537   \n",
       "8  BOND_008 2027-02-15     0.057331     2   ACT/365  100.844864  100.829027   \n",
       "9  BOND_009 2030-02-15     0.079338     2    30/360  110.717796  110.695757   \n",
       "\n",
       "    accrued flags  \n",
       "0  0.010606        \n",
       "1  0.010196        \n",
       "2  0.009803        \n",
       "3  0.012973        \n",
       "4  0.013965        \n",
       "5  0.014781        \n",
       "6  0.022147        \n",
       "7  0.018767        \n",
       "8  0.015837        \n",
       "9  0.022038        "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pricing portfolio with QC flags (loop now, vectorize next)\n",
    "\n",
    "def price_portfolio(pricer: BondPricer, portfolio: pd.DataFrame, val_date: pd.Timestamp, settle: pd.Timestamp) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in portfolio.iterrows():\n",
    "        bond = Bond(\n",
    "            bond_id=str(r[\"bond_id\"]),\n",
    "            maturity=pd.Timestamp(r[\"maturity\"]),\n",
    "            coupon_rate=float(r[\"coupon_rate\"]),\n",
    "            freq=int(r[\"freq\"]),\n",
    "            day_count=str(r[\"day_count\"]),\n",
    "            face=float(r[\"face\"]),\n",
    "        )\n",
    "\n",
    "        flags = []\n",
    "        try:\n",
    "            dirty, clean, ai = pricer.price(bond, val_date, settle)\n",
    "            if dirty < 0 or clean < 0:\n",
    "                flags.append(\"NEGATIVE_PRICE\")\n",
    "            if dirty < 20 or dirty > 200 or clean < 20 or clean > 200:\n",
    "                flags.append(\"EXTREME_PRICE\")\n",
    "        except Exception as e:\n",
    "            dirty, clean, ai = np.nan, np.nan, np.nan\n",
    "            flags.append(type(e).__name__)  # e.g., ValueError, NotImplementedError\n",
    "\n",
    "        rows.append({\n",
    "            \"bond_id\": bond.bond_id,\n",
    "            \"maturity\": bond.maturity,\n",
    "            \"coupon_rate\": bond.coupon_rate,\n",
    "            \"freq\": bond.freq,\n",
    "            \"day_count\": bond.day_count,\n",
    "            \"dirty\": dirty,\n",
    "            \"clean\": clean,\n",
    "            \"accrued\": ai,\n",
    "            \"flags\": \"|\".join(flags) if flags else \"\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "settle = pd.Timestamp(\"2026-02-16\")  # use a non-coupon day to see accrued > 0 on many bonds\n",
    "pricer = BondPricer(curve)\n",
    "\n",
    "priced = price_portfolio(pricer, portfolio_df, val_date, settle)\n",
    "priced.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b74d99a-3e41-4e22-b301-5db83380cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 total, 20 ok\n",
      "88.51152546462357 124.86797996182032\n"
     ]
    }
   ],
   "source": [
    "ok = priced[priced[\"flags\"] == \"\"]\n",
    "print(len(priced), \"total,\", len(ok), \"ok\")\n",
    "print(ok[\"clean\"].min(), ok[\"clean\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d1590e3-96be-4a53-839f-b5efd96f5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC function that produces explicit flags\n",
    "\n",
    "def qc_flags_for_bond(bond: Bond, settle: pd.Timestamp) -> List[str]:\n",
    "    flags = []\n",
    "\n",
    "    if settle >= bond.maturity:\n",
    "        flags.append(\"MATURED\")\n",
    "\n",
    "    if bond.freq not in (1, 2, 4):\n",
    "        flags.append(\"BAD_FREQ\")\n",
    "\n",
    "    if bond.coupon_rate < -0.01 or bond.coupon_rate > 0.25:\n",
    "        flags.append(\"BAD_COUPON\")\n",
    "\n",
    "    # schedule checks (only if not matured)\n",
    "    if \"MATURED\" not in flags:\n",
    "        dates = coupon_schedule_after_settlement(settle, bond.maturity, bond.freq)\n",
    "        if len(dates) == 0:\n",
    "            flags.append(\"NO_CASHFLOWS\")\n",
    "        else:\n",
    "            if dates[-1] != pd.Timestamp(bond.maturity):\n",
    "                flags.append(\"BAD_DATES\")\n",
    "            if any(dates[i] >= dates[i+1] for i in range(len(dates)-1)):\n",
    "                flags.append(\"BAD_DATES\")\n",
    "\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bde498f7-1e35-41ce-85d0-93fb5cc7089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule cache\n",
    "## Most portfolios have repeated maturity dates in reality\n",
    "## So we cache schedules by (settle, maturity, freq).\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=100_000)\n",
    "def cached_schedule(settle: pd.Timestamp, maturity: pd.Timestamp, freq: int) -> Tuple[pd.Timestamp, ...]:\n",
    "    # lru_cache needs hashable objects; Timestamp is hashable\n",
    "    dates = coupon_schedule_after_settlement(pd.Timestamp(settle), pd.Timestamp(maturity), int(freq))\n",
    "    return tuple(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d74117-d85f-46c2-b3d1-445eb93e712e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vectorized Portfolio Pricing Strategy\n",
    "\n",
    "Instead of pricing each bond separately:\n",
    "1. Expand the portfolio into a cashflow table (one row per cashflow).\n",
    "2. Call the curve discount factor function once for all unique payment dates.\n",
    "3. Compute PVs in a vectorized way and aggregate by bond.\n",
    "\n",
    "This pattern scales because:\n",
    "- It reduces Python loops.\n",
    "- It amortizes curve interpolation cost.\n",
    "- It makes QC and scenario shocks easy (modify $D(t)$ or cashflows and recompute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1052ac41-690d-4290-b717-da5cb0594b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>face</th>\n",
       "      <th>pay_date</th>\n",
       "      <th>cashflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2026-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2027-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2027-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2028-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2029-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2029-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2030-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2030-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count   face   pay_date  \\\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2026-08-15   \n",
       "1  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2027-02-15   \n",
       "2  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2027-08-15   \n",
       "3  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2028-02-15   \n",
       "4  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2028-08-15   \n",
       "5  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2029-02-15   \n",
       "6  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2029-08-15   \n",
       "7  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2030-02-15   \n",
       "8  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2030-08-15   \n",
       "9  BOND_000 2036-02-15     0.038182     2    30/360  100.0 2031-02-15   \n",
       "\n",
       "   cashflow  \n",
       "0  1.909097  \n",
       "1  1.909097  \n",
       "2  1.909097  \n",
       "3  1.909097  \n",
       "4  1.909097  \n",
       "5  1.909097  \n",
       "6  1.909097  \n",
       "7  1.909097  \n",
       "8  1.909097  \n",
       "9  1.909097  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Cashflow table\n",
    "\n",
    "def build_cashflow_table(portfolio: pd.DataFrame, settle: pd.Timestamp) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in portfolio.iterrows():\n",
    "        bond_id = str(r[\"bond_id\"])\n",
    "        maturity = pd.Timestamp(r[\"maturity\"])\n",
    "        c = float(r[\"coupon_rate\"])\n",
    "        freq = int(r[\"freq\"])\n",
    "        face = float(r[\"face\"])\n",
    "\n",
    "        # basic QC: skip matured here; flag later\n",
    "        if settle >= maturity:\n",
    "            continue\n",
    "\n",
    "        pay_dates = cached_schedule(settle, maturity, freq)\n",
    "        if len(pay_dates) == 0:\n",
    "            continue\n",
    "\n",
    "        coupon_cf = face * (c / freq)\n",
    "        for i, d in enumerate(pay_dates):\n",
    "            cf = coupon_cf\n",
    "            if i == len(pay_dates) - 1:\n",
    "                cf += face\n",
    "            rows.append((bond_id, maturity, c, freq, str(r[\"day_count\"]), face, pd.Timestamp(d), cf))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\"bond_id\", \"maturity\", \"coupon_rate\", \"freq\", \"day_count\", \"face\", \"pay_date\", \"cashflow\"]\n",
    "    )\n",
    "\n",
    "cf_table = build_cashflow_table(portfolio_df, settle)\n",
    "cf_table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0949ee59-1e14-4c7c-8550-87d46709d6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>face</th>\n",
       "      <th>pv</th>\n",
       "      <th>dirty</th>\n",
       "      <th>accrued</th>\n",
       "      <th>clean</th>\n",
       "      <th>flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.504154</td>\n",
       "      <td>94.504154</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>94.493547</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.369914</td>\n",
       "      <td>94.369914</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>94.359718</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.035292</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.539742</td>\n",
       "      <td>93.539742</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>93.529938</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.923368</td>\n",
       "      <td>100.923368</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>100.910395</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>2032-02-15</td>\n",
       "      <td>0.050273</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.723256</td>\n",
       "      <td>101.723256</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>101.709291</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOND_005</td>\n",
       "      <td>2034-02-15</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.870534</td>\n",
       "      <td>104.870534</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>104.855754</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>124.890127</td>\n",
       "      <td>124.890127</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>124.867980</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOND_007</td>\n",
       "      <td>2029-02-15</td>\n",
       "      <td>0.067560</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.305304</td>\n",
       "      <td>104.305304</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>104.286537</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOND_008</td>\n",
       "      <td>2027-02-15</td>\n",
       "      <td>0.057331</td>\n",
       "      <td>2</td>\n",
       "      <td>ACT/365</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.844864</td>\n",
       "      <td>100.844864</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>100.829027</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOND_009</td>\n",
       "      <td>2030-02-15</td>\n",
       "      <td>0.079338</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.717796</td>\n",
       "      <td>110.717796</td>\n",
       "      <td>0.022038</td>\n",
       "      <td>110.695757</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count   face          pv  \\\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360  100.0   94.504154   \n",
       "1  BOND_001 2033-02-15     0.036706     2    30/360  100.0   94.369914   \n",
       "2  BOND_002 2033-02-15     0.035292     2    30/360  100.0   93.539742   \n",
       "3  BOND_003 2035-02-15     0.046705     2    30/360  100.0  100.923368   \n",
       "4  BOND_004 2032-02-15     0.050273     2    30/360  100.0  101.723256   \n",
       "5  BOND_005 2034-02-15     0.053210     2    30/360  100.0  104.870534   \n",
       "6  BOND_006 2035-02-15     0.079730     2    30/360  100.0  124.890127   \n",
       "7  BOND_007 2029-02-15     0.067560     2    30/360  100.0  104.305304   \n",
       "8  BOND_008 2027-02-15     0.057331     2   ACT/365  100.0  100.844864   \n",
       "9  BOND_009 2030-02-15     0.079338     2    30/360  100.0  110.717796   \n",
       "\n",
       "        dirty   accrued       clean flags  \n",
       "0   94.504154  0.010606   94.493547        \n",
       "1   94.369914  0.010196   94.359718        \n",
       "2   93.539742  0.009803   93.529938        \n",
       "3  100.923368  0.012973  100.910395        \n",
       "4  101.723256  0.013965  101.709291        \n",
       "5  104.870534  0.014781  104.855754        \n",
       "6  124.890127  0.022147  124.867980        \n",
       "7  104.305304  0.018767  104.286537        \n",
       "8  100.844864  0.015837  100.829027        \n",
       "9  110.717796  0.022038  110.695757        "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorized PV + dirty price (settlement-adjusted)\n",
    "\n",
    "def price_portfolio_vectorized(curve: ZeroCurve, portfolio: pd.DataFrame, val_date: pd.Timestamp, settle: pd.Timestamp) -> pd.DataFrame:\n",
    "    settle = pd.Timestamp(settle)\n",
    "\n",
    "    # Cashflow expansion\n",
    "    cf = build_cashflow_table(portfolio, settle)\n",
    "    if cf.empty:\n",
    "        raise ValueError(\"Cashflow table is empty. Check portfolio or settlement/maturity logic.\")\n",
    "\n",
    "    # Discount factors for all unique pay dates in one shot\n",
    "    unique_dates = sorted(cf[\"pay_date\"].unique())\n",
    "    df_pay = curve.df(unique_dates)\n",
    "    df_map = dict(zip(unique_dates, df_pay))\n",
    "\n",
    "    # Settlement DF for adjustment\n",
    "    df_settle = float(curve.df([settle])[0])\n",
    "\n",
    "    # Map D(T) and compute settlement-adjusted DF\n",
    "    cf[\"df_pay\"] = cf[\"pay_date\"].map(df_map).astype(float)\n",
    "    cf[\"df_settle_adj\"] = cf[\"df_pay\"] / df_settle\n",
    "    cf[\"pv_cf\"] = cf[\"cashflow\"] * cf[\"df_settle_adj\"]\n",
    "\n",
    "    # Aggregate PV per bond\n",
    "    pv_by_bond = cf.groupby(\"bond_id\", as_index=False)[\"pv_cf\"].sum().rename(columns={\"pv_cf\": \"pv\"})\n",
    "\n",
    "    # Merge back bond static info (one row per bond)\n",
    "    static_cols = [\"bond_id\", \"maturity\", \"coupon_rate\", \"freq\", \"day_count\", \"face\"]\n",
    "    out = portfolio[static_cols].merge(pv_by_bond, on=\"bond_id\", how=\"left\")\n",
    "\n",
    "    # Dirty per 100\n",
    "    out[\"dirty\"] = 100.0 * out[\"pv\"] / out[\"face\"]\n",
    "\n",
    "    # Accrued per 100 (still per bond; keep as loop for correctness, optimize later)\n",
    "    accrued_list = []\n",
    "    flag_list = []\n",
    "    for _, r in out.iterrows():\n",
    "        bond = Bond(\n",
    "            bond_id=str(r[\"bond_id\"]),\n",
    "            maturity=pd.Timestamp(r[\"maturity\"]),\n",
    "            coupon_rate=float(r[\"coupon_rate\"]),\n",
    "            freq=int(r[\"freq\"]),\n",
    "            day_count=str(r[\"day_count\"]),\n",
    "            face=float(r[\"face\"]),\n",
    "        )\n",
    "\n",
    "        flags = qc_flags_for_bond(bond, settle)\n",
    "\n",
    "        if \"MATURED\" in flags:\n",
    "            accrued_list.append(np.nan)\n",
    "        else:\n",
    "            ai_amt = accrued_interest(settle, bond.maturity, bond.coupon_rate, bond.face, bond.freq, bond.day_count)\n",
    "            accrued_list.append(100.0 * ai_amt / bond.face)\n",
    "\n",
    "        flag_list.append(\"|\".join(flags) if flags else \"\")\n",
    "\n",
    "    out[\"accrued\"] = accrued_list\n",
    "    out[\"clean\"] = out[\"dirty\"] - out[\"accrued\"]\n",
    "    out[\"flags\"] = flag_list\n",
    "\n",
    "    # Additional QC flags based on outputs\n",
    "    out.loc[out[\"dirty\"] < 0, \"flags\"] = out[\"flags\"].where(out[\"flags\"] != \"\", \"\") + \"|NEGATIVE_PRICE\"\n",
    "    out.loc[out[\"dirty\"] > 200, \"flags\"] = out[\"flags\"].where(out[\"flags\"] != \"\", \"\") + \"|EXTREME_PRICE\"\n",
    "    out[\"flags\"] = out[\"flags\"].str.strip(\"|\")\n",
    "\n",
    "    return out\n",
    "\n",
    "priced_vec = price_portfolio_vectorized(curve, portfolio_df, val_date, settle)\n",
    "priced_vec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7021a938-62e5-469b-a651-b2041c02c0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>dirty_diff</th>\n",
       "      <th>clean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOND_005</td>\n",
       "      <td>-1.421085e-14</td>\n",
       "      <td>-1.421085e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOND_007</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOND_008</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOND_009</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id    dirty_diff    clean_diff\n",
       "0  BOND_000  0.000000e+00  0.000000e+00\n",
       "1  BOND_001  0.000000e+00  0.000000e+00\n",
       "2  BOND_002  0.000000e+00  0.000000e+00\n",
       "3  BOND_003  0.000000e+00  0.000000e+00\n",
       "4  BOND_004  0.000000e+00  0.000000e+00\n",
       "5  BOND_005 -1.421085e-14 -1.421085e-14\n",
       "6  BOND_006  0.000000e+00  0.000000e+00\n",
       "7  BOND_007  0.000000e+00  0.000000e+00\n",
       "8  BOND_008  0.000000e+00  0.000000e+00\n",
       "9  BOND_009  0.000000e+00  0.000000e+00"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare loop pricing vs vectorized pricing on the first 10 bonds:\n",
    "\n",
    "priced_loop = price_portfolio(pricer, portfolio_df, val_date, settle)\n",
    "\n",
    "cmp = priced_loop.merge(\n",
    "    priced_vec[[\"bond_id\", \"dirty\", \"clean\", \"accrued\", \"flags\"]],\n",
    "    on=\"bond_id\",\n",
    "    suffixes=(\"_loop\", \"_vec\"),\n",
    ")\n",
    "\n",
    "cmp[\"dirty_diff\"] = cmp[\"dirty_loop\"] - cmp[\"dirty_vec\"]\n",
    "cmp[\"clean_diff\"] = cmp[\"clean_loop\"] - cmp[\"clean_vec\"]\n",
    "cmp[[\"bond_id\", \"dirty_diff\", \"clean_diff\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710f699-f001-4daa-ad22-d54fa8ae8f0d",
   "metadata": {},
   "source": [
    "# **IV. Risk Measures (Duration, DV01, Convexity)**\n",
    "\n",
    "## Why This Matters\n",
    "Valuation teams are not judged on price alone.\n",
    "They must explain and control sensitivity of prices to:\n",
    "\n",
    "- Parallel rate shifts\n",
    "- Curve shape changes\n",
    "- Spread shocks (later)\n",
    "- Scenario stress testing\n",
    "\n",
    "We implement:\n",
    "\n",
    "1) Macaulay Duration\n",
    "2) Modified Duration\n",
    "3) DV01 (Dollar Value of 1bp)\n",
    "4) Convexity\n",
    "5) Finite-difference validation checks\n",
    "\n",
    "---\n",
    "\n",
    "## Definitions\n",
    "\n",
    "Let settlement-adjusted discount factors be:\n",
    "$$\n",
    "D_s(T) = \\frac{D(T)}{D(s)}\n",
    "$$\n",
    "\n",
    "Dirty price:\n",
    "$$\n",
    "P = \\sum_i CF_i D_s(t_i)\n",
    "$$\n",
    "\n",
    "### Macaulay Duration\n",
    "$$\n",
    "D_{Mac} = \\frac{1}{P}\\sum_i t_i CF_i D_s(t_i)\n",
    "$$\n",
    "\n",
    "### Modified Duration\n",
    "If yield is $y$:\n",
    "$$\n",
    "D_{mod} = \\frac{D_{Mac}}{1 + \\frac{y}{m}}\n",
    "$$\n",
    "\n",
    "But in a curve-based framework, we define duration via price sensitivity:\n",
    "$$\n",
    "D_{mod} = -\\frac{1}{P}\\frac{\\partial P}{\\partial y}\n",
    "$$\n",
    "\n",
    "### DV01\n",
    "$$\n",
    "DV01 = -\\frac{\\partial P}{\\partial y} \\cdot 0.0001\n",
    "$$\n",
    "\n",
    "### Convexity\n",
    "$$\n",
    "Conv = \\frac{1}{P}\\frac{\\partial^2 P}{\\partial y^2}\n",
    "$$\n",
    "\n",
    "We compute both analytical (cashflow-weighted) and finite-difference versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "191449f2-f642-4340-8588-9285362b7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel curve shock function\n",
    "\n",
    "def shocked_curve_parallel(curve: ZeroCurve, shift_bp: float) -> ZeroCurve:\n",
    "    \"\"\"\n",
    "    Parallel shift in continuously-compounded zero rates.\n",
    "    shift_bp in basis points (e.g., +1.0 for +1bp).\n",
    "    \"\"\"\n",
    "    shift = shift_bp / 10000.0  # convert bp to decimal\n",
    "\n",
    "    # Convert knot DFs to zero rates\n",
    "    dates = pd.to_datetime(curve.knot_dates)\n",
    "    dfs = np.exp(curve.knot_log_dfs)\n",
    "\n",
    "    taus = np.array([\n",
    "        yearfrac(curve.val_date, d, curve.zero_day_count)\n",
    "        for d in dates\n",
    "    ])\n",
    "\n",
    "    zeros = -np.log(dfs) / taus\n",
    "\n",
    "    # Apply parallel shift\n",
    "    zeros_shifted = zeros + shift\n",
    "\n",
    "    # Rebuild discount factors\n",
    "    dfs_shifted = np.exp(-zeros_shifted * taus)\n",
    "\n",
    "    logdfs_shifted = np.log(dfs_shifted)\n",
    "\n",
    "    return ZeroCurve(\n",
    "        val_date=curve.val_date,\n",
    "        knot_dates=curve.knot_dates.copy(),\n",
    "        knot_log_dfs=logdfs_shifted,\n",
    "        zero_day_count=curve.zero_day_count,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f0194a5-32bf-42d3-921f-a207c8e93610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>dirty_base</th>\n",
       "      <th>dirty_up1bp</th>\n",
       "      <th>dv01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>94.504154</td>\n",
       "      <td>94.425087</td>\n",
       "      <td>-0.079067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>94.369914</td>\n",
       "      <td>94.311254</td>\n",
       "      <td>-0.058660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>93.539742</td>\n",
       "      <td>93.481378</td>\n",
       "      <td>-0.058364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>100.923368</td>\n",
       "      <td>100.847944</td>\n",
       "      <td>-0.075424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>101.723256</td>\n",
       "      <td>101.669695</td>\n",
       "      <td>-0.053561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id  dirty_base  dirty_up1bp      dv01\n",
       "0  BOND_000   94.504154    94.425087 -0.079067\n",
       "1  BOND_001   94.369914    94.311254 -0.058660\n",
       "2  BOND_002   93.539742    93.481378 -0.058364\n",
       "3  BOND_003  100.923368   100.847944 -0.075424\n",
       "4  BOND_004  101.723256   101.669695 -0.053561"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DV01 via finite difference (vectorized)\n",
    "\n",
    "def compute_portfolio_dv01(curve: ZeroCurve, portfolio: pd.DataFrame, val_date: pd.Timestamp, settle: pd.Timestamp):\n",
    "    base = price_portfolio_vectorized(curve, portfolio, val_date, settle)\n",
    "\n",
    "    shocked = shocked_curve_parallel(curve, shift_bp=1.0)\n",
    "    shocked_prices = price_portfolio_vectorized(shocked, portfolio, val_date, settle)\n",
    "\n",
    "    out = base[[\"bond_id\", \"dirty\"]].merge(\n",
    "        shocked_prices[[\"bond_id\", \"dirty\"]],\n",
    "        on=\"bond_id\",\n",
    "        suffixes=(\"_base\", \"_up1bp\")\n",
    "    )\n",
    "\n",
    "    out[\"dv01\"] = out[\"dirty_up1bp\"] - out[\"dirty_base\"]\n",
    "\n",
    "    return out\n",
    "\n",
    "dv01_df = compute_portfolio_dv01(curve, portfolio_df, val_date, settle)\n",
    "dv01_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbe7db96-4a76-4313-ac09-ae9ddf9247d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08624893020329694 -0.009667087959343235\n"
     ]
    }
   ],
   "source": [
    "print(dv01_df[\"dv01\"].min(), dv01_df[\"dv01\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06508a63-4287-43c7-ab3f-b3e1d8d59cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>convexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>78.385251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>41.673294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>41.894041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>62.760942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>30.077598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id  convexity\n",
       "0  BOND_000  78.385251\n",
       "1  BOND_001  41.673294\n",
       "2  BOND_002  41.894041\n",
       "3  BOND_003  62.760942\n",
       "4  BOND_004  30.077598"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Convexity (Finite Difference)\n",
    "## We will compute convexity using symmetric finite differences\n",
    "## This measures curvature and validates duration linearity.\n",
    "\n",
    "def compute_portfolio_convexity(curve: ZeroCurve, portfolio: pd.DataFrame, val_date: pd.Timestamp, settle: pd.Timestamp):\n",
    "    base = price_portfolio_vectorized(curve, portfolio, val_date, settle)\n",
    "\n",
    "    up = shocked_curve_parallel(curve, shift_bp=1.0)\n",
    "    down = shocked_curve_parallel(curve, shift_bp=-1.0)\n",
    "\n",
    "    price_up = price_portfolio_vectorized(up, portfolio, val_date, settle)\n",
    "    price_down = price_portfolio_vectorized(down, portfolio, val_date, settle)\n",
    "\n",
    "    out = base[[\"bond_id\", \"dirty\"]].merge(\n",
    "        price_up[[\"bond_id\", \"dirty\"]],\n",
    "        on=\"bond_id\",\n",
    "        suffixes=(\"_base\", \"_up\")\n",
    "    ).merge(\n",
    "        price_down[[\"bond_id\", \"dirty\"]],\n",
    "        on=\"bond_id\"\n",
    "    )\n",
    "\n",
    "    out = out.rename(columns={\"dirty\": \"dirty_down\"})\n",
    "\n",
    "    h = 0.0001\n",
    "\n",
    "    out[\"convexity\"] = (\n",
    "        out[\"dirty_up\"] + out[\"dirty_down\"] - 2 * out[\"dirty_base\"]\n",
    "    ) / (out[\"dirty_base\"] * h**2)\n",
    "\n",
    "    return out[[\"bond_id\", \"convexity\"]]\n",
    "\n",
    "conv_df = compute_portfolio_convexity(curve, portfolio_df, val_date, settle)\n",
    "conv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6286ee78-2d8f-4a7e-b8a3-6b3da851f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9736964691923332), np.float64(78.38525120875688))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_df[\"convexity\"].min(), conv_df[\"convexity\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac538ded-70ad-4cfc-987f-a55000131a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>mod_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>8.366467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>6.215978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>6.239485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>7.473386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>5.265350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id  mod_duration\n",
       "0  BOND_000      8.366467\n",
       "1  BOND_001      6.215978\n",
       "2  BOND_002      6.239485\n",
       "3  BOND_003      7.473386\n",
       "4  BOND_004      5.265350"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duration from DV01 (Consistency Check)\n",
    "\n",
    "def duration_from_dv01(dv01_df: pd.DataFrame):\n",
    "    df = dv01_df.copy()\n",
    "    df[\"mod_duration\"] = -df[\"dv01\"] / (df[\"dirty_base\"] * 0.0001)\n",
    "    return df[[\"bond_id\", \"mod_duration\"]]\n",
    "\n",
    "dur_df = duration_from_dv01(dv01_df)\n",
    "dur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d08dd-07fb-4135-b1d5-03c9b1624316",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **V. Scenario Analysis (Rate, Curve Shape and Credit Spread)**\n",
    "\n",
    "## Goal\n",
    "Compute scenario P&L for each bond and the total portfolio under:\n",
    "- Parallel rate shocks: ±25bp, ±50bp\n",
    "- Steepener / flattener (curve shape changes)\n",
    "- (Next step) Credit spread widening for corporate bonds\n",
    "\n",
    "## Design principle\n",
    "We do **not** re-implement pricing. We reuse:\n",
    "- cashflow table expansion\n",
    "- settlement-adjusted discounting\n",
    "- curve object with interpolation policy\n",
    "\n",
    "Scenario engine only modifies the curve (or spreads), then calls the same pricing function.\n",
    "\n",
    "## P&L convention\n",
    "We define:\n",
    "$$\n",
    "\\Delta P = P_{\\text{shocked}} - P_{\\text{base}}\n",
    "$$\n",
    "Negative means loss for a long bond under rate increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f179fac7-b6d5-4e8b-8df6-19d0f96fac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothetical zero-rate shock builder\n",
    "\n",
    "def curve_from_shifted_zeros(curve: ZeroCurve, shift_func) -> ZeroCurve:\n",
    "    \"\"\"\n",
    "    Build a new curve by shifting continuously-compounded zero rates z(t)\n",
    "    by shift_func(tau) (in decimal).\n",
    "    \"\"\"\n",
    "    dates = pd.to_datetime(curve.knot_dates)\n",
    "    dfs = np.exp(curve.knot_log_dfs)\n",
    "\n",
    "    taus = np.array([yearfrac(curve.val_date, d, curve.zero_day_count) for d in dates], dtype=float)\n",
    "    zeros = -np.log(dfs) / taus\n",
    "\n",
    "    shifts = np.array([shift_func(t) for t in taus], dtype=float)\n",
    "    zeros_shifted = zeros + shifts\n",
    "\n",
    "    dfs_shifted = np.exp(-zeros_shifted * taus)\n",
    "    logdfs_shifted = np.log(dfs_shifted)\n",
    "\n",
    "    return ZeroCurve(\n",
    "        val_date=curve.val_date,\n",
    "        knot_dates=curve.knot_dates.copy(),\n",
    "        knot_log_dfs=logdfs_shifted,\n",
    "        zero_day_count=curve.zero_day_count,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82c293e7-00fe-45d5-9ba7-a598cb74bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario shock functions\n",
    "\n",
    "def parallel_shift_bp(bp: float):\n",
    "    s = bp / 10000.0\n",
    "    return lambda tau: s\n",
    "\n",
    "def steepener_shift_bp(bp: float, pivot: float = 2.0, long: float = 10.0):\n",
    "    \"\"\"\n",
    "    Steepener: short end up +bp, long end down -bp.\n",
    "    Piecewise linear between pivot and long.\n",
    "    \"\"\"\n",
    "    A = bp / 10000.0\n",
    "\n",
    "    def f(tau: float) -> float:\n",
    "        if tau <= pivot:\n",
    "            return +A\n",
    "        if tau >= long:\n",
    "            return -A\n",
    "        w = (tau - pivot) / (long - pivot)\n",
    "        return (1 - w) * (+A) + w * (-A)\n",
    "\n",
    "    return f\n",
    "\n",
    "def flattener_shift_bp(bp: float, pivot: float = 2.0, long: float = 10.0):\n",
    "    \"\"\"\n",
    "    Flattener: short end down -bp, long end up +bp.\n",
    "    \"\"\"\n",
    "    A = bp / 10000.0\n",
    "\n",
    "    def f(tau: float) -> float:\n",
    "        if tau <= pivot:\n",
    "            return -A\n",
    "        if tau >= long:\n",
    "            return +A\n",
    "        w = (tau - pivot) / (long - pivot)\n",
    "        return (1 - w) * (-A) + w * (+A)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "829d362f-7c10-4d47-881e-0aa892614c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>total_pnl_per_100_notional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAR_-50bp_PnL</td>\n",
       "      <td>52.431716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAR_-25bp_PnL</td>\n",
       "      <td>25.989558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAR_+25bp_PnL</td>\n",
       "      <td>-25.545758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAR_+50bp_PnL</td>\n",
       "      <td>-50.656334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STEEPENER_25bp_PnL</td>\n",
       "      <td>8.904997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FLATTENER_25bp_PnL</td>\n",
       "      <td>-8.653248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scenario  total_pnl_per_100_notional\n",
       "0       PAR_-50bp_PnL                   52.431716\n",
       "1       PAR_-25bp_PnL                   25.989558\n",
       "2       PAR_+25bp_PnL                  -25.545758\n",
       "3       PAR_+50bp_PnL                  -50.656334\n",
       "4  STEEPENER_25bp_PnL                    8.904997\n",
       "5  FLATTENER_25bp_PnL                   -8.653248"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scenario runner (vectorized)\n",
    "## scenario pricing + P&L table\n",
    "\n",
    "def run_rate_scenarios(\n",
    "    curve: ZeroCurve,\n",
    "    portfolio: pd.DataFrame,\n",
    "    val_date: pd.Timestamp,\n",
    "    settle: pd.Timestamp,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - per-bond scenario table (base + shocked prices + P&L)\n",
    "      - portfolio summary (total P&L per scenario)\n",
    "    \"\"\"\n",
    "    base = price_portfolio_vectorized(curve, portfolio, val_date, settle)[[\"bond_id\", \"dirty\"]].rename(columns={\"dirty\": \"base\"})\n",
    "\n",
    "    scenarios = {\n",
    "        \"PAR_-50bp\": curve_from_shifted_zeros(curve, parallel_shift_bp(-50)),\n",
    "        \"PAR_-25bp\": curve_from_shifted_zeros(curve, parallel_shift_bp(-25)),\n",
    "        \"PAR_+25bp\": curve_from_shifted_zeros(curve, parallel_shift_bp(+25)),\n",
    "        \"PAR_+50bp\": curve_from_shifted_zeros(curve, parallel_shift_bp(+50)),\n",
    "        \"STEEPENER_25bp\": curve_from_shifted_zeros(curve, steepener_shift_bp(25)),\n",
    "        \"FLATTENER_25bp\": curve_from_shifted_zeros(curve, flattener_shift_bp(25)),\n",
    "    }\n",
    "\n",
    "    per_bond = base.copy()\n",
    "\n",
    "    for name, scurve in scenarios.items():\n",
    "        px = price_portfolio_vectorized(scurve, portfolio, val_date, settle)[[\"bond_id\", \"dirty\"]].rename(columns={\"dirty\": name})\n",
    "        per_bond = per_bond.merge(px, on=\"bond_id\", how=\"left\")\n",
    "        per_bond[name + \"_PnL\"] = per_bond[name] - per_bond[\"base\"]\n",
    "\n",
    "    # Portfolio totals\n",
    "    pnl_cols = [c for c in per_bond.columns if c.endswith(\"_PnL\")]\n",
    "    summary = pd.DataFrame({\n",
    "        \"scenario\": pnl_cols,\n",
    "        \"total_pnl_per_100_notional\": [per_bond[c].sum() for c in pnl_cols],\n",
    "    })\n",
    "\n",
    "    return per_bond, summary\n",
    "\n",
    "per_bond_scen, scen_summary = run_rate_scenarios(curve, portfolio_df, val_date, settle)\n",
    "scen_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "adba952a-fa96-4d3c-a9fb-bd0d25f41e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>PAR_+25bp_PnL</th>\n",
       "      <th>dv01</th>\n",
       "      <th>linear_25bp</th>\n",
       "      <th>nonlinear_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>-1.954627</td>\n",
       "      <td>-0.079067</td>\n",
       "      <td>-1.976665</td>\n",
       "      <td>0.022038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>-1.454775</td>\n",
       "      <td>-0.058660</td>\n",
       "      <td>-1.466503</td>\n",
       "      <td>0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>-1.447413</td>\n",
       "      <td>-0.058364</td>\n",
       "      <td>-1.459100</td>\n",
       "      <td>0.011687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>-1.866738</td>\n",
       "      <td>-0.075424</td>\n",
       "      <td>-1.885598</td>\n",
       "      <td>0.018860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>-1.329889</td>\n",
       "      <td>-0.053561</td>\n",
       "      <td>-1.339021</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOND_005</td>\n",
       "      <td>-1.733014</td>\n",
       "      <td>-0.069943</td>\n",
       "      <td>-1.748584</td>\n",
       "      <td>0.015570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>-2.131881</td>\n",
       "      <td>-0.086106</td>\n",
       "      <td>-2.152641</td>\n",
       "      <td>0.020761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOND_007</td>\n",
       "      <td>-0.719858</td>\n",
       "      <td>-0.028895</td>\n",
       "      <td>-0.722371</td>\n",
       "      <td>0.002513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOND_008</td>\n",
       "      <td>-0.247591</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>-0.247885</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOND_009</td>\n",
       "      <td>-0.973753</td>\n",
       "      <td>-0.039128</td>\n",
       "      <td>-0.978209</td>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id  PAR_+25bp_PnL      dv01  linear_25bp  nonlinear_diff\n",
       "0  BOND_000      -1.954627 -0.079067    -1.976665        0.022038\n",
       "1  BOND_001      -1.454775 -0.058660    -1.466503        0.011728\n",
       "2  BOND_002      -1.447413 -0.058364    -1.459100        0.011687\n",
       "3  BOND_003      -1.866738 -0.075424    -1.885598        0.018860\n",
       "4  BOND_004      -1.329889 -0.053561    -1.339021        0.009132\n",
       "5  BOND_005      -1.733014 -0.069943    -1.748584        0.015570\n",
       "6  BOND_006      -2.131881 -0.086106    -2.152641        0.020761\n",
       "7  BOND_007      -0.719858 -0.028895    -0.722371        0.002513\n",
       "8  BOND_008      -0.247591 -0.009915    -0.247885        0.000294\n",
       "9  BOND_009      -0.973753 -0.039128    -0.978209        0.004456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    20.000000\n",
       "mean      0.010579\n",
       "std       0.008128\n",
       "min       0.000288\n",
       "25%       0.002487\n",
       "50%       0.010410\n",
       "75%       0.018122\n",
       "max       0.023448\n",
       "Name: nonlinear_diff, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exposure summary (DV01 approximation vs scenario)\n",
    "\n",
    "# Compare +25bp scenario vs DV01 linear approx\n",
    "dv01_df = compute_portfolio_dv01(curve, portfolio_df, val_date, settle)\n",
    "\n",
    "tmp = per_bond_scen[[\"bond_id\", \"PAR_+25bp_PnL\"]].merge(dv01_df[[\"bond_id\", \"dv01\"]], on=\"bond_id\")\n",
    "tmp[\"linear_25bp\"] = 25.0 * tmp[\"dv01\"]\n",
    "tmp[\"nonlinear_diff\"] = tmp[\"PAR_+25bp_PnL\"] - tmp[\"linear_25bp\"]\n",
    "\n",
    "display(tmp.head(10), tmp[\"nonlinear_diff\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf66035-306b-40dc-a5f5-e7748d3dce95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Results — Scenario Analysis Results & Risk Interpretation\n",
    "\n",
    "## 1. Parallel Rate Shock Sanity Check\n",
    "\n",
    "Portfolio P&L (per 100 notional):\n",
    "\n",
    "| Scenario | Total P&L |\n",
    "|-----------|------------|\n",
    "| -50bp     | +52.43     |\n",
    "| -25bp     | +25.99     |\n",
    "| +25bp     | -25.55     |\n",
    "| +50bp     | -50.66     |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "1. **Directional consistency**\n",
    "   - Rate decreases → portfolio gains\n",
    "   - Rate increases → portfolio losses  \n",
    "   This confirms the portfolio is net **long duration**.\n",
    "\n",
    "2. **Near symmetry**\n",
    "   - Loss at +50bp ≈ -50.66  \n",
    "   - Gain at -50bp ≈ +52.43  \n",
    "\n",
    "   The magnitudes are close but not identical.\n",
    "\n",
    "3. **Convexity effect**\n",
    "   The asymmetry arises from convexity:\n",
    "\n",
    "   $$\n",
    "   \\Delta P \\approx -D \\Delta y + \\frac{1}{2} C (\\Delta y)^2\n",
    "   $$\n",
    "\n",
    "   Because convexity $C > 0$ for standard fixed-rate bonds:\n",
    "   - Gains from rate decreases are slightly larger\n",
    "   - Losses from rate increases are slightly smaller than linear duration prediction\n",
    "\n",
    "   This is expected and confirms second-order risk behavior is working correctly.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Linear Approximation vs True Scenario\n",
    "\n",
    "For +25bp:\n",
    "\n",
    "$$\n",
    "\\Delta P_{\\text{linear}} \\approx 25 \\times DV01\n",
    "$$\n",
    "\n",
    "Observed nonlinear adjustment statistics:\n",
    "\n",
    "- Mean convexity adjustment ≈ 0.0106\n",
    "- Max ≈ 0.0234\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "The difference:\n",
    "\n",
    "$$\n",
    "\\Delta P_{\\text{true}} - 25 \\cdot DV01 > 0\n",
    "$$\n",
    "\n",
    "This means the linear approximation slightly **overstates the loss**, which is consistent with positive convexity.\n",
    "\n",
    "If this sign were reversed, it would indicate:\n",
    "- Incorrect convexity implementation\n",
    "- Numerical instability\n",
    "- Discounting inconsistency\n",
    "\n",
    "The current behavior is correct and internally consistent.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Curve Shape Scenarios\n",
    "\n",
    "| Scenario          | Total P&L |\n",
    "|-------------------|------------|\n",
    "| Steepener +25bp   | +8.90      |\n",
    "| Flattener +25bp   | -8.65      |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Steepener logic:\n",
    "- Short end ↑\n",
    "- Long end ↓\n",
    "\n",
    "Because the portfolio contains a large concentration of long-maturity bonds (2033–2036 range), it benefits more from long-end declines than it loses from short-end increases.\n",
    "\n",
    "Flattener produces the opposite effect.\n",
    "\n",
    "This confirms:\n",
    "- Curve tilt mechanics are functioning\n",
    "- Portfolio duration distribution is realistic\n",
    "- Risk exposure is maturity-sensitive, not purely parallel\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Validation Checks\n",
    "\n",
    "The scenario engine passes the following internal consistency checks:\n",
    "\n",
    "1. Directionally correct P&L  \n",
    "2. Convexity asymmetry present  \n",
    "3. Linear vs nonlinear reconciliation consistent  \n",
    "4. Curve shape shocks produce maturity-sensitive effects  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca90e26-40f9-469f-811a-e0e300145255",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **VI. Key Rate Duration (Institutional Implementation)**\n",
    "\n",
    "Parallel DV01 measures total curve sensitivity.\n",
    "\n",
    "Key Rate Duration decomposes that sensitivity into localized maturity buckets.\n",
    "\n",
    "Unlike parallel shifts, key rate shocks must be:\n",
    "\n",
    "- Localized\n",
    "- Smooth\n",
    "- Independent of interpolation artifacts\n",
    "\n",
    "We implement triangular bucket shocks centered at key maturities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "558e31b8-dd75-4617-899a-f6634430d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangular Key Rate Shock\n",
    "\n",
    "def triangular_key_rate_shift(curve: ZeroCurve, key_index: int, bp: float):\n",
    "    \"\"\"\n",
    "    Apply triangular zero-rate bump centered at knot index key_index.\n",
    "    \"\"\"\n",
    "    s = bp / 10000.0\n",
    "\n",
    "    dates = pd.to_datetime(curve.knot_dates)\n",
    "    dfs = np.exp(curve.knot_log_dfs)\n",
    "\n",
    "    taus = np.array([yearfrac(curve.val_date, d, curve.zero_day_count) for d in dates])\n",
    "    zeros = -np.log(dfs) / taus\n",
    "\n",
    "    zeros_shifted = zeros.copy()\n",
    "\n",
    "    for i in range(len(taus)):\n",
    "        if i == key_index:\n",
    "            zeros_shifted[i] += s\n",
    "        elif i == key_index - 1:\n",
    "            zeros_shifted[i] += 0.5 * s\n",
    "        elif i == key_index + 1:\n",
    "            zeros_shifted[i] += 0.5 * s\n",
    "\n",
    "    dfs_shifted = np.exp(-zeros_shifted * taus)\n",
    "    logdfs_shifted = np.log(dfs_shifted)\n",
    "\n",
    "    return ZeroCurve(\n",
    "        curve.val_date,\n",
    "        curve.knot_dates.copy(),\n",
    "        logdfs_shifted,\n",
    "        curve.zero_day_count,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6da09f8a-d67d-416d-aefc-243ed2baa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bucketed KRD\n",
    "\n",
    "def compute_key_rate_duration(curve, portfolio, val_date, settle):\n",
    "    base = price_portfolio_vectorized(curve, portfolio, val_date, settle)[[\"bond_id\", \"dirty\"]]\n",
    "    base = base.rename(columns={\"dirty\": \"base\"})\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx in range(len(curve.knot_dates)):\n",
    "        shifted_curve = triangular_key_rate_shift(curve, idx, 1.0)\n",
    "        shocked = price_portfolio_vectorized(shifted_curve, portfolio, val_date, settle)[[\"bond_id\", \"dirty\"]]\n",
    "        shocked = shocked.rename(columns={\"dirty\": \"shocked\"})\n",
    "\n",
    "        tmp = base.merge(shocked, on=\"bond_id\")\n",
    "        tmp[\"krd\"] = tmp[\"shocked\"] - tmp[\"base\"]\n",
    "        tmp[\"bucket_index\"] = idx\n",
    "\n",
    "        results.append(tmp[[\"bond_id\", \"bucket_index\", \"krd\"]])\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00e71d6d-9c91-4f76-99b6-9ec807d38078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bucket_index\n",
       "0    0.001671\n",
       "1    0.000835\n",
       "2   -0.001198\n",
       "3   -0.015221\n",
       "4   -0.073500\n",
       "5   -0.282506\n",
       "6   -0.678380\n",
       "7   -0.734307\n",
       "Name: krd, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krd_df = compute_key_rate_duration(curve, portfolio_df, val_date, settle)\n",
    "\n",
    "portfolio_krd = krd_df.groupby(\"bucket_index\")[\"krd\"].sum()\n",
    "portfolio_krd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc179924-f331-493a-9286-54630efb203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-1.782607763975264)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_krd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6b15209-92a1-4304-808f-2c1f00656760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel 1bp DV01: -1.0302933377672616\n"
     ]
    }
   ],
   "source": [
    "parallel_1bp_curve = curve_from_shifted_zeros(curve, parallel_shift_bp(1.0))\n",
    "base = price_portfolio_vectorized(curve, portfolio_df, val_date, settle)[\"dirty\"].sum()\n",
    "shocked = price_portfolio_vectorized(parallel_1bp_curve, portfolio_df, val_date, settle)[\"dirty\"].sum()\n",
    "\n",
    "print(\"Parallel 1bp DV01:\", shocked - base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced5248-5b0b-4056-a045-4736c08fff77",
   "metadata": {},
   "source": [
    "## Key Rate Duration (KRD) — Partition-of-Unity Basis\n",
    "\n",
    "Naively bumping individual knots causes overlap and double-counting, so bucket DV01s will not reconcile to parallel DV01.\n",
    "\n",
    "We implement piecewise-linear \"hat\" basis functions over knot maturities. These basis functions satisfy:\n",
    "\n",
    "$$\n",
    "\\sum_k b_k(\\tau) = 1\n",
    "$$\n",
    "\n",
    "Therefore, the sum of bucket DV01s approximately equals the parallel DV01:\n",
    "\n",
    "$$\n",
    "\\sum_k KRD_k \\approx DV01_{\\text{parallel}}\n",
    "$$\n",
    "\n",
    "This reconciliation is a critical institutional validation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa1136d4-5698-4622-9d51-820ed129404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hat basis function\n",
    "\n",
    "def hat_basis(taus: np.ndarray, k: int):\n",
    "    \"\"\"\n",
    "    Returns a function b_k(tau) for piecewise-linear hat basis on taus grid.\n",
    "    \"\"\"\n",
    "    n = len(taus)\n",
    "    if not (0 <= k < n):\n",
    "        raise ValueError(\"k out of range\")\n",
    "\n",
    "    def b(tau: float) -> float:\n",
    "        if k == 0:\n",
    "            if tau <= taus[0]:\n",
    "                return 1.0\n",
    "            if tau >= taus[1]:\n",
    "                return 0.0\n",
    "            return (taus[1] - tau) / (taus[1] - taus[0])\n",
    "\n",
    "        if k == n - 1:\n",
    "            if tau <= taus[n - 2]:\n",
    "                return 0.0\n",
    "            if tau >= taus[n - 1]:\n",
    "                return 1.0\n",
    "            return (tau - taus[n - 2]) / (taus[n - 1] - taus[n - 2])\n",
    "\n",
    "        # interior\n",
    "        if tau <= taus[k - 1] or tau >= taus[k + 1]:\n",
    "            return 0.0\n",
    "        if tau <= taus[k]:\n",
    "            return (tau - taus[k - 1]) / (taus[k] - taus[k - 1])\n",
    "        else:\n",
    "            return (taus[k + 1] - tau) / (taus[k + 1] - taus[k])\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af032a78-8982-4259-b873-13526828a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply KRD bump using basis\n",
    "\n",
    "def key_rate_curve_hat(curve: ZeroCurve, k: int, bp: float) -> ZeroCurve:\n",
    "    \"\"\"\n",
    "    Apply +bp shock to zero rates using hat basis b_k(tau).\n",
    "    \"\"\"\n",
    "    s = bp / 10000.0\n",
    "\n",
    "    dates = pd.to_datetime(curve.knot_dates)\n",
    "    dfs = np.exp(curve.knot_log_dfs)\n",
    "\n",
    "    taus = np.array([yearfrac(curve.val_date, d, curve.zero_day_count) for d in dates], dtype=float)\n",
    "    zeros = -np.log(dfs) / taus\n",
    "\n",
    "    b_k = hat_basis(taus, k)\n",
    "    shifts = np.array([b_k(t) for t in taus], dtype=float) * s\n",
    "\n",
    "    zeros_shifted = zeros + shifts\n",
    "\n",
    "    dfs_shifted = np.exp(-zeros_shifted * taus)\n",
    "    logdfs_shifted = np.log(dfs_shifted)\n",
    "\n",
    "    return ZeroCurve(curve.val_date, curve.knot_dates.copy(), logdfs_shifted, curve.zero_day_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e85b11f2-d4a4-4e9d-bf6f-1b6da88084f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket sum: -1.0303758845650464\n",
      "Parallel DV01: -1.0302933377672616\n",
      "Difference: -8.254679778474383e-05\n"
     ]
    }
   ],
   "source": [
    "# compute KRD table + reconciliation\n",
    "\n",
    "def compute_krd_hat(curve: ZeroCurve, portfolio: pd.DataFrame, val_date: pd.Timestamp, settle: pd.Timestamp, bp: float = 1.0):\n",
    "    base_total = price_portfolio_vectorized(curve, portfolio, val_date, settle)[\"dirty\"].sum()\n",
    "\n",
    "    bucket_pnl = []\n",
    "    for k in range(len(curve.knot_dates)):\n",
    "        scurve = key_rate_curve_hat(curve, k, bp)\n",
    "        shocked_total = price_portfolio_vectorized(scurve, portfolio, val_date, settle)[\"dirty\"].sum()\n",
    "        bucket_pnl.append(shocked_total - base_total)\n",
    "\n",
    "    bucket_pnl = np.array(bucket_pnl, dtype=float)\n",
    "\n",
    "    # parallel DV01 for the same bp\n",
    "    par_curve = curve_from_shifted_zeros(curve, parallel_shift_bp(bp))\n",
    "    par_total = price_portfolio_vectorized(par_curve, portfolio, val_date, settle)[\"dirty\"].sum()\n",
    "    par_dv01 = par_total - base_total\n",
    "\n",
    "    return bucket_pnl, par_dv01\n",
    "\n",
    "bucket_pnl, par_dv01 = compute_krd_hat(curve, portfolio_df, val_date, settle, bp=1.0)\n",
    "\n",
    "print(\"Bucket sum:\", bucket_pnl.sum())\n",
    "print(\"Parallel DV01:\", par_dv01)\n",
    "print(\"Difference:\", bucket_pnl.sum() - par_dv01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bb40b-fb76-41f2-a021-cc522f6bc959",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Key Rate Duration Results (KRD) (Bucketed DV01)\n",
    "\n",
    "## 1. Why KRD exists\n",
    "Parallel DV01 measures total sensitivity to a uniform shift in rates.  \n",
    "Key Rate Duration decomposes that exposure into maturity buckets, which is essential for:\n",
    "- hedging (choosing specific tenors)\n",
    "- understanding curve-shape risk\n",
    "- risk reporting and stress testing\n",
    "\n",
    "## 2. Implementation detail (institutional requirement)\n",
    "Naively bumping individual knots can **double-count** exposure and fails to reconcile to parallel DV01.\n",
    "\n",
    "We therefore used piecewise-linear \"hat\" basis functions $b_k(\\tau)$ defined on the curve knot maturities such that:\n",
    "\n",
    "$$\n",
    "\\sum_k b_k(\\tau) = 1 \\quad \\text{(partition of unity)}\n",
    "$$\n",
    "\n",
    "A +1bp key-rate shock is implemented as a localized bump in continuously-compounded zero rates:\n",
    "\n",
    "$$\n",
    "z'(\\tau) = z(\\tau) + 0.0001 \\cdot b_k(\\tau)\n",
    "$$\n",
    "\n",
    "This preserves curve structure and avoids arbitrary interpolation artifacts.\n",
    "\n",
    "## 3. Critical validation: KRD must reconcile to parallel DV01\n",
    "We validated:\n",
    "\n",
    "- Sum of bucket P&Ls under +1bp bumps:\n",
    "  $$\\sum_k KRD_k = -1.030376$$\n",
    "- Portfolio parallel DV01 under +1bp:\n",
    "  $$DV01_{parallel} = -1.030293$$\n",
    "\n",
    "Difference:\n",
    "$$\n",
    "\\sum_k KRD_k - DV01_{parallel} \\approx -8.25 \\times 10^{-5}\n",
    "$$\n",
    "\n",
    "This is within numerical tolerance and confirms the KRD decomposition is consistent.\n",
    "\n",
    "## 4. Interpretation\n",
    "- Buckets with larger negative values contribute more to portfolio rate risk.\n",
    "- Concentration of negative bucket DV01 at long maturities implies the portfolio is long duration and long-end exposed.\n",
    "- This bucket decomposition is the foundation for tenor hedging (e.g., hedging with 5Y vs 10Y vs long bond exposures).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f7fab59-1059-4c3c-8437-e2f4a95b40e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>knot_date</th>\n",
       "      <th>tau_years</th>\n",
       "      <th>bucket_dv01</th>\n",
       "      <th>bucket_dv01_pct_of_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>-0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-03-13</td>\n",
       "      <td>0.076712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-05-15</td>\n",
       "      <td>0.249315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-08-14</td>\n",
       "      <td>0.498630</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>-0.025649</td>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>2.005479</td>\n",
       "      <td>-0.093303</td>\n",
       "      <td>0.090553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>5.008219</td>\n",
       "      <td>-0.352736</td>\n",
       "      <td>0.342337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>10.010959</td>\n",
       "      <td>-0.557962</td>\n",
       "      <td>0.541513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  knot_date  tau_years  bucket_dv01  bucket_dv01_pct_of_total\n",
       "0             0 2026-02-20   0.019178     0.001671                 -0.001621\n",
       "1             1 2026-03-13   0.076712     0.000000                 -0.000000\n",
       "2             2 2026-05-15   0.249315     0.000000                 -0.000000\n",
       "3             3 2026-08-14   0.498630    -0.002396                  0.002326\n",
       "4             4 2027-02-12   0.997260    -0.025649                  0.024893\n",
       "5             5 2028-02-15   2.005479    -0.093303                  0.090553\n",
       "6             6 2031-02-15   5.008219    -0.352736                  0.342337\n",
       "7             7 2036-02-15  10.010959    -0.557962                  0.541513"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exposure table\n",
    "\n",
    "# Build readable bucket table\n",
    "knot_dates = pd.to_datetime(curve.knot_dates)\n",
    "knot_taus = np.array([yearfrac(curve.val_date, d, curve.zero_day_count) for d in knot_dates], dtype=float)\n",
    "\n",
    "bucket_table = pd.DataFrame({\n",
    "    \"bucket_index\": np.arange(len(bucket_pnl)),\n",
    "    \"knot_date\": knot_dates,\n",
    "    \"tau_years\": knot_taus,\n",
    "    \"bucket_dv01\": bucket_pnl,  # per 100 notional for +1bp localized bucket shock\n",
    "})\n",
    "\n",
    "bucket_table[\"bucket_dv01_pct_of_total\"] = bucket_table[\"bucket_dv01\"] / bucket_table[\"bucket_dv01\"].sum()\n",
    "bucket_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc39a1db-41b0-4d78-b9ef-2f15dec90e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>knot_date</th>\n",
       "      <th>tau_years</th>\n",
       "      <th>bucket_dv01</th>\n",
       "      <th>bucket_dv01_pct_of_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>10.010959</td>\n",
       "      <td>-0.557962</td>\n",
       "      <td>0.541513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>5.008219</td>\n",
       "      <td>-0.352736</td>\n",
       "      <td>0.342337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>2.005479</td>\n",
       "      <td>-0.093303</td>\n",
       "      <td>0.090553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>-0.025649</td>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-08-14</td>\n",
       "      <td>0.498630</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.002326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-03-13</td>\n",
       "      <td>0.076712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-05-15</td>\n",
       "      <td>0.249315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>-0.001621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  knot_date  tau_years  bucket_dv01  bucket_dv01_pct_of_total\n",
       "0             7 2036-02-15  10.010959    -0.557962                  0.541513\n",
       "1             6 2031-02-15   5.008219    -0.352736                  0.342337\n",
       "2             5 2028-02-15   2.005479    -0.093303                  0.090553\n",
       "3             4 2027-02-12   0.997260    -0.025649                  0.024893\n",
       "4             3 2026-08-14   0.498630    -0.002396                  0.002326\n",
       "5             1 2026-03-13   0.076712     0.000000                 -0.000000\n",
       "6             2 2026-05-15   0.249315     0.000000                 -0.000000\n",
       "7             0 2026-02-20   0.019178     0.001671                 -0.001621"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show concentration\n",
    "\n",
    "bucket_table.sort_values(\"bucket_dv01\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1057cb-29ec-441d-aba3-c212238c1067",
   "metadata": {},
   "source": [
    "# **VII. Corporate Bond Pricing (Spread Over Risk-Free Curve)**\n",
    "\n",
    "## Objective\n",
    "Extend the pricing engine to value corporate bonds by discounting cashflows using:\n",
    "- the risk-free discount curve $D(t)$\n",
    "- a constant credit spread $s$ applied to **all** cashflows (Z-spread style)\n",
    "\n",
    "## Why spreads are applied to all cashflows\n",
    "A corporate bond is a stream of risky cashflows. Each cashflow is subject to:\n",
    "- default risk\n",
    "- liquidity risk\n",
    "- funding/valuation adjustments (in production)\n",
    "\n",
    "Therefore spread is applied to every cashflow date $t_i$:\n",
    "\n",
    "## Spread-adjusted discount factor\n",
    "Using settlement-adjusted discounting and a constant spread $s$ (in decimal):\n",
    "\n",
    "$$\n",
    "D_{corp}(t_i) = \\frac{D(t_i)}{D(s)} \\cdot e^{-s \\cdot \\tau(s, t_i)}\n",
    "$$\n",
    "\n",
    "where $\\tau(s,t_i)$ is the year fraction from settlement to the cashflow date under the curve day count basis.\n",
    "\n",
    "## Interpretation\n",
    "- This is the standard \"discount margin\" / Z-spread intuition.\n",
    "- In practice, OAS extends this by using a stochastic rate model and subtracting the embedded option value.\n",
    "  Here we implement the deterministic baseline first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c442df97-2257-426e-a414-5538144339b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corporate bond definition\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class CorporateBond(Bond):\n",
    "    spread: float = 0.0  # constant credit spread in decimal (e.g. 0.015 = 150bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dfcf8d1-d785-4a74-a5ff-8bea1285644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spread-adjusted pricing function (vectorized-friendly)\n",
    "\n",
    "def price_corporate_bond_dirty_clean(\n",
    "    curve: ZeroCurve,\n",
    "    bond: CorporateBond,\n",
    "    val_date: pd.Timestamp,\n",
    "    settle: Optional[pd.Timestamp] = None,\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Corporate bond pricing with constant spread applied to ALL cashflows:\n",
    "      D_corp(t) = D(t)/D(settle) * exp(-spread * tau(settle,t))\n",
    "\n",
    "    Returns (dirty, clean, accrued) per 100.\n",
    "    \"\"\"\n",
    "    if settle is None:\n",
    "        settle = settlement_date(val_date, 2)\n",
    "\n",
    "    settle = pd.Timestamp(settle)\n",
    "    if settle >= bond.maturity:\n",
    "        raise ValueError(f\"{bond.bond_id}: matured at settlement.\")\n",
    "\n",
    "    if bond.spread < -0.001:\n",
    "        raise ValueError(\"Suspicious negative spread.\")\n",
    "\n",
    "    pay_dates = coupon_schedule_after_settlement(settle, bond.maturity, bond.freq)\n",
    "    coupon_cf = bond.face * (bond.coupon_rate / bond.freq)\n",
    "\n",
    "    cfs = np.full(len(pay_dates), coupon_cf, dtype=float)\n",
    "    cfs[-1] += bond.face\n",
    "\n",
    "    # base settlement-adjusted DFs\n",
    "    df_pay = curve.df(pay_dates)\n",
    "    df_settle = float(curve.df([settle])[0])\n",
    "    df_settle_adj = df_pay / df_settle\n",
    "\n",
    "    # spread adjustment applied to all cashflows\n",
    "    taus_settle = np.array([yearfrac(settle, d, curve.zero_day_count) for d in pay_dates], dtype=float)\n",
    "    spread_adj = np.exp(-bond.spread * taus_settle)\n",
    "\n",
    "    dfs_corp = df_settle_adj * spread_adj\n",
    "\n",
    "    pv = float(np.sum(cfs * dfs_corp))\n",
    "    dirty = 100.0 * pv / bond.face\n",
    "\n",
    "    ai_amt = accrued_interest(settle, bond.maturity, bond.coupon_rate, bond.face, bond.freq, bond.day_count)\n",
    "    ai = 100.0 * ai_amt / bond.face\n",
    "    clean = dirty - ai\n",
    "\n",
    "    return dirty, clean, ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "691514a4-4a34-4d84-a0b8-6f2cec76f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread   0bp -> Dirty 100.953156, Clean 100.939267, AI 0.013889\n",
      "Spread  50bp -> Dirty 98.713017, Clean 98.699128, AI 0.013889\n",
      "Spread 100bp -> Dirty 96.525972, Clean 96.512083, AI 0.013889\n",
      "Spread 200bp -> Dirty 92.306058, Clean 92.292169, AI 0.013889\n"
     ]
    }
   ],
   "source": [
    "# Demo: price a corporate bond at different spreads\n",
    "\n",
    "corp = CorporateBond(\n",
    "    bond_id=\"CORP_5Y_5PCT\",\n",
    "    maturity=pd.Timestamp(\"2031-02-15\"),\n",
    "    coupon_rate=0.05,\n",
    "    freq=2,\n",
    "    day_count=\"30/360\",\n",
    "    face=100.0,\n",
    "    spread=0.0\n",
    ")\n",
    "\n",
    "settle = pd.Timestamp(\"2026-02-16\")\n",
    "\n",
    "for s_bp in [0, 50, 100, 200]:\n",
    "    corp_s = CorporateBond(**{**corp.__dict__, \"spread\": s_bp/10000.0})\n",
    "    dirty, clean, ai = price_corporate_bond_dirty_clean(curve, corp_s, val_date, settle)\n",
    "    print(f\"Spread {s_bp:>3}bp -> Dirty {dirty:.6f}, Clean {clean:.6f}, AI {ai:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d8d5483f-1162-423f-98a8-9973eeb792bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spread DV01: -0.04218490904337102 Spread Duration: 4.46917892480038\n"
     ]
    }
   ],
   "source": [
    "# Spread DV01 / Spread Duration\n",
    "\n",
    "def spread_dv01(curve: ZeroCurve, bond: CorporateBond, val_date: pd.Timestamp, settle: pd.Timestamp) -> float:\n",
    "    base_dirty, _, _ = price_corporate_bond_dirty_clean(curve, bond, val_date, settle)\n",
    "    bumped = CorporateBond(**{**bond.__dict__, \"spread\": bond.spread + 1/10000.0})\n",
    "    bumped_dirty, _, _ = price_corporate_bond_dirty_clean(curve, bumped, val_date, settle)\n",
    "    return bumped_dirty - base_dirty\n",
    "\n",
    "def spread_duration(curve: ZeroCurve, bond: CorporateBond, val_date: pd.Timestamp, settle: pd.Timestamp) -> float:\n",
    "    base_dirty, _, _ = price_corporate_bond_dirty_clean(curve, bond, val_date, settle)\n",
    "    sdv01 = spread_dv01(curve, bond, val_date, settle)\n",
    "    return -sdv01 / (base_dirty * 0.0001)\n",
    "\n",
    "corp_150 = CorporateBond(**{**corp.__dict__, \"spread\": 150/10000.0})\n",
    "sdv01 = spread_dv01(curve, corp_150, val_date, settle)\n",
    "sdur = spread_duration(curve, corp_150, val_date, settle)\n",
    "print(\"Spread DV01:\", sdv01, \"Spread Duration:\", sdur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f803f-61ed-43e2-a847-4a903ce4e41b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Corporate Portfolio Pricing at Scale\n",
    "\n",
    "To scale corporate bond valuation, we reuse the same vectorized cashflow table approach:\n",
    "\n",
    "Dirty price:\n",
    "$$\n",
    "P = \\sum_i CF_i \\cdot \\frac{D(t_i)}{D(s)} \\cdot e^{-s \\cdot \\tau(s,t_i)}\n",
    "$$\n",
    "\n",
    "Key observation:\n",
    "- Risk-free discounting and cashflow generation are identical to the Treasury case.\n",
    "- Credit spread enters only through a multiplicative factor $e^{-s\\tau}$ applied to every cashflow.\n",
    "\n",
    "This makes spread shocks extremely efficient:\n",
    "- rate shocks modify $D(t)$\n",
    "- spread shocks modify $s$\n",
    "- combined shocks modify both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4fd3ee0a-798d-4612-bac4-1e2495f6de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>face</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.013984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.035292</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.016233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>2032-02-15</td>\n",
       "      <td>0.050273</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.006254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count   face    spread\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829\n",
       "1  BOND_001 2033-02-15     0.036706     2    30/360  100.0  0.013984\n",
       "2  BOND_002 2033-02-15     0.035292     2    30/360  100.0  0.016233\n",
       "3  BOND_003 2035-02-15     0.046705     2    30/360  100.0  0.003631\n",
       "4  BOND_004 2032-02-15     0.050273     2    30/360  100.0  0.006254"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorized corporate portfolio pricing\n",
    "\n",
    "def add_random_spreads(portfolio: pd.DataFrame, seed: int = 11) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = portfolio.copy()\n",
    "    # IG-ish spreads: 30bp to 250bp\n",
    "    out[\"spread\"] = rng.uniform(30, 250, size=len(out)) / 10000.0\n",
    "    return out\n",
    "\n",
    "corp_portfolio_df = add_random_spreads(portfolio_df)\n",
    "corp_portfolio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "669c59bd-cb80-4411-97fa-2a828a71e05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>face</th>\n",
       "      <th>spread</th>\n",
       "      <th>pay_date</th>\n",
       "      <th>cashflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>2026-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>2027-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>2027-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>2028-08-15</td>\n",
       "      <td>1.909097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count   face    spread  \\\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829   \n",
       "1  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829   \n",
       "2  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829   \n",
       "3  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829   \n",
       "4  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829   \n",
       "\n",
       "    pay_date  cashflow  \n",
       "0 2026-08-15  1.909097  \n",
       "1 2027-02-15  1.909097  \n",
       "2 2027-08-15  1.909097  \n",
       "3 2028-02-15  1.909097  \n",
       "4 2028-08-15  1.909097  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corporate cashflow table (same as before, just keep spread)\n",
    "\n",
    "def build_cashflow_table_corp(portfolio: pd.DataFrame, settle: pd.Timestamp) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in portfolio.iterrows():\n",
    "        bond_id = str(r[\"bond_id\"])\n",
    "        maturity = pd.Timestamp(r[\"maturity\"])\n",
    "        c = float(r[\"coupon_rate\"])\n",
    "        freq = int(r[\"freq\"])\n",
    "        face = float(r[\"face\"])\n",
    "        dc = str(r[\"day_count\"])\n",
    "        spr = float(r[\"spread\"])\n",
    "\n",
    "        if settle >= maturity:\n",
    "            continue\n",
    "\n",
    "        pay_dates = cached_schedule(settle, maturity, freq)\n",
    "        if len(pay_dates) == 0:\n",
    "            continue\n",
    "\n",
    "        coupon_cf = face * (c / freq)\n",
    "        for i, d in enumerate(pay_dates):\n",
    "            cf = coupon_cf\n",
    "            if i == len(pay_dates) - 1:\n",
    "                cf += face\n",
    "            rows.append((bond_id, maturity, c, freq, dc, face, spr, pd.Timestamp(d), cf))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\"bond_id\",\"maturity\",\"coupon_rate\",\"freq\",\"day_count\",\"face\",\"spread\",\"pay_date\",\"cashflow\"]\n",
    "    )\n",
    "\n",
    "cf_corp = build_cashflow_table_corp(corp_portfolio_df, settle)\n",
    "cf_corp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8218b2c4-9559-47a4-9f0c-0fcd428f1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized corporate pricing\n",
    "\n",
    "def price_corporate_portfolio_vectorized(\n",
    "    curve: ZeroCurve,\n",
    "    portfolio: pd.DataFrame,\n",
    "    val_date: pd.Timestamp,\n",
    "    settle: pd.Timestamp,\n",
    ") -> pd.DataFrame:\n",
    "    settle = pd.Timestamp(settle)\n",
    "\n",
    "    cf = build_cashflow_table_corp(portfolio, settle)\n",
    "    if cf.empty:\n",
    "        raise ValueError(\"Corporate cashflow table is empty.\")\n",
    "\n",
    "    # discount factors for all unique pay dates\n",
    "    unique_dates = sorted(cf[\"pay_date\"].unique())\n",
    "    df_pay = curve.df(unique_dates)\n",
    "    df_map = dict(zip(unique_dates, df_pay))\n",
    "\n",
    "    df_settle = float(curve.df([settle])[0])\n",
    "\n",
    "    cf[\"df_pay\"] = cf[\"pay_date\"].map(df_map).astype(float)\n",
    "    cf[\"df_settle_adj\"] = cf[\"df_pay\"] / df_settle\n",
    "\n",
    "    # tau from settle to pay_date for spread factor\n",
    "    cf[\"tau_settle\"] = cf[\"pay_date\"].apply(lambda d: yearfrac(settle, d, curve.zero_day_count)).astype(float)\n",
    "    cf[\"spread_adj\"] = np.exp(-cf[\"spread\"].astype(float) * cf[\"tau_settle\"])\n",
    "\n",
    "    cf[\"pv_cf\"] = cf[\"cashflow\"] * cf[\"df_settle_adj\"] * cf[\"spread_adj\"]\n",
    "\n",
    "    pv_by_bond = cf.groupby(\"bond_id\", as_index=False)[\"pv_cf\"].sum().rename(columns={\"pv_cf\": \"pv\"})\n",
    "\n",
    "    static_cols = [\"bond_id\",\"maturity\",\"coupon_rate\",\"freq\",\"day_count\",\"face\",\"spread\"]\n",
    "    out = portfolio[static_cols].merge(pv_by_bond, on=\"bond_id\", how=\"left\")\n",
    "    out[\"dirty\"] = 100.0 * out[\"pv\"] / out[\"face\"]\n",
    "\n",
    "    # accrued per 100\n",
    "    accrued = []\n",
    "    flags = []\n",
    "    for _, r in out.iterrows():\n",
    "        bond = Bond(\n",
    "            bond_id=str(r[\"bond_id\"]),\n",
    "            maturity=pd.Timestamp(r[\"maturity\"]),\n",
    "            coupon_rate=float(r[\"coupon_rate\"]),\n",
    "            freq=int(r[\"freq\"]),\n",
    "            day_count=str(r[\"day_count\"]),\n",
    "            face=float(r[\"face\"]),\n",
    "        )\n",
    "        f = qc_flags_for_bond(bond, settle)\n",
    "        flags.append(\"|\".join(f) if f else \"\")\n",
    "\n",
    "        if \"MATURED\" in f:\n",
    "            accrued.append(np.nan)\n",
    "        else:\n",
    "            ai_amt = accrued_interest(settle, bond.maturity, bond.coupon_rate, bond.face, bond.freq, bond.day_count)\n",
    "            accrued.append(100.0 * ai_amt / bond.face)\n",
    "\n",
    "    out[\"accrued\"] = accrued\n",
    "    out[\"clean\"] = out[\"dirty\"] - out[\"accrued\"]\n",
    "    out[\"flags\"] = flags\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19b7d013-5416-41f6-8877-1dd060d02ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>maturity</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>freq</th>\n",
       "      <th>day_count</th>\n",
       "      <th>face</th>\n",
       "      <th>spread</th>\n",
       "      <th>pv</th>\n",
       "      <th>dirty</th>\n",
       "      <th>accrued</th>\n",
       "      <th>clean</th>\n",
       "      <th>flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>90.017060</td>\n",
       "      <td>90.017060</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>90.006454</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOND_001</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>86.536609</td>\n",
       "      <td>86.536609</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>86.526413</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOND_002</td>\n",
       "      <td>2033-02-15</td>\n",
       "      <td>0.035292</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.016233</td>\n",
       "      <td>84.560044</td>\n",
       "      <td>84.560044</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>84.550241</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.046705</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>98.224779</td>\n",
       "      <td>98.224779</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>98.211806</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOND_004</td>\n",
       "      <td>2032-02-15</td>\n",
       "      <td>0.050273</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>98.431521</td>\n",
       "      <td>98.431521</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>98.417556</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOND_005</td>\n",
       "      <td>2034-02-15</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.023421</td>\n",
       "      <td>89.833634</td>\n",
       "      <td>89.833634</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>89.818854</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>2035-02-15</td>\n",
       "      <td>0.079730</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>121.042595</td>\n",
       "      <td>121.042595</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>121.020448</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOND_007</td>\n",
       "      <td>2029-02-15</td>\n",
       "      <td>0.067560</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>102.627568</td>\n",
       "      <td>102.627568</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>102.608802</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOND_008</td>\n",
       "      <td>2027-02-15</td>\n",
       "      <td>0.057331</td>\n",
       "      <td>2</td>\n",
       "      <td>ACT/365</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.023863</td>\n",
       "      <td>98.506347</td>\n",
       "      <td>98.506347</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>98.490510</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOND_009</td>\n",
       "      <td>2030-02-15</td>\n",
       "      <td>0.079338</td>\n",
       "      <td>2</td>\n",
       "      <td>30/360</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>104.392322</td>\n",
       "      <td>104.392322</td>\n",
       "      <td>0.022038</td>\n",
       "      <td>104.370284</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bond_id   maturity  coupon_rate  freq day_count   face    spread  \\\n",
       "0  BOND_000 2036-02-15     0.038182     2    30/360  100.0  0.005829   \n",
       "1  BOND_001 2033-02-15     0.036706     2    30/360  100.0  0.013984   \n",
       "2  BOND_002 2033-02-15     0.035292     2    30/360  100.0  0.016233   \n",
       "3  BOND_003 2035-02-15     0.046705     2    30/360  100.0  0.003631   \n",
       "4  BOND_004 2032-02-15     0.050273     2    30/360  100.0  0.006254   \n",
       "5  BOND_005 2034-02-15     0.053210     2    30/360  100.0  0.023421   \n",
       "6  BOND_006 2035-02-15     0.079730     2    30/360  100.0  0.004549   \n",
       "7  BOND_007 2029-02-15     0.067560     2    30/360  100.0  0.005855   \n",
       "8  BOND_008 2027-02-15     0.057331     2   ACT/365  100.0  0.023863   \n",
       "9  BOND_009 2030-02-15     0.079338     2    30/360  100.0  0.016681   \n",
       "\n",
       "           pv       dirty   accrued       clean flags  \n",
       "0   90.017060   90.017060  0.010606   90.006454        \n",
       "1   86.536609   86.536609  0.010196   86.526413        \n",
       "2   84.560044   84.560044  0.009803   84.550241        \n",
       "3   98.224779   98.224779  0.012973   98.211806        \n",
       "4   98.431521   98.431521  0.013965   98.417556        \n",
       "5   89.833634   89.833634  0.014781   89.818854        \n",
       "6  121.042595  121.042595  0.022147  121.020448        \n",
       "7  102.627568  102.627568  0.018767  102.608802        \n",
       "8   98.506347   98.506347  0.015837   98.490510        \n",
       "9  104.392322  104.392322  0.022038  104.370284        "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_priced = price_corporate_portfolio_vectorized(curve, corp_portfolio_df, val_date, settle)\n",
    "corp_priced.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6c87880-1897-426a-9d6a-5bd293b74909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>total_pnl_per_100_notional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPR_+25bp_PnL</td>\n",
       "      <td>-23.464322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPR_+100bp_PnL</td>\n",
       "      <td>-91.516137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario  total_pnl_per_100_notional\n",
       "0   SPR_+25bp_PnL                  -23.464322\n",
       "1  SPR_+100bp_PnL                  -91.516137"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spread scenario shocks (portfolio)\n",
    "\n",
    "def run_spread_scenarios(\n",
    "    curve: ZeroCurve,\n",
    "    corp_portfolio: pd.DataFrame,\n",
    "    val_date: pd.Timestamp,\n",
    "    settle: pd.Timestamp,\n",
    "):\n",
    "    base = price_corporate_portfolio_vectorized(curve, corp_portfolio, val_date, settle)[[\"bond_id\",\"dirty\"]]\n",
    "    base = base.rename(columns={\"dirty\":\"base\"})\n",
    "\n",
    "    scenarios = {\n",
    "        \"SPR_+25bp\": 25/10000.0,\n",
    "        \"SPR_+100bp\": 100/10000.0,\n",
    "    }\n",
    "\n",
    "    per_bond = base.copy()\n",
    "\n",
    "    for name, bump in scenarios.items():\n",
    "        shocked_port = corp_portfolio.copy()\n",
    "        shocked_port[\"spread\"] = shocked_port[\"spread\"] + bump\n",
    "\n",
    "        shocked = price_corporate_portfolio_vectorized(curve, shocked_port, val_date, settle)[[\"bond_id\",\"dirty\"]]\n",
    "        shocked = shocked.rename(columns={\"dirty\": name})\n",
    "\n",
    "        per_bond = per_bond.merge(shocked, on=\"bond_id\")\n",
    "        per_bond[name + \"_PnL\"] = per_bond[name] - per_bond[\"base\"]\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"scenario\": [c for c in per_bond.columns if c.endswith(\"_PnL\")],\n",
    "        \"total_pnl_per_100_notional\": [per_bond[c].sum() for c in per_bond.columns if c.endswith(\"_PnL\")]\n",
    "    })\n",
    "\n",
    "    return per_bond, summary\n",
    "\n",
    "spread_per_bond, spread_summary = run_spread_scenarios(curve, corp_portfolio_df, val_date, settle)\n",
    "spread_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603c59c-c8a8-43ac-94b4-26452817b856",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combined Rate + Spread Scenarios (Valuation Desk Style)\n",
    "\n",
    "Corporate bond valuation is driven by two major risk channels:\n",
    "1) Risk-free curve movements (rates)\n",
    "2) Credit spread movements (spread widening/tightening)\n",
    "\n",
    "We therefore report scenario P&L under combinations such as:\n",
    "- Rates +50bp with spreads +25bp (risk-off shock)\n",
    "- Rates -50bp with spreads -25bp (risk-on shock)\n",
    "\n",
    "Mechanically:\n",
    "- Rate shocks modify the risk-free curve $D(t)$\n",
    "- Spread shocks modify the spread term $e^{-s \\tau}$ applied to every cashflow\n",
    "\n",
    "The pricing engine remains unchanged; only inputs are shocked.\n",
    "This is critical for production infrastructure: one pricing pipeline, many scenario views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a9c2121-fcfc-467e-a7fa-456ae93355c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_shock_bp</th>\n",
       "      <th>spread_shock_bp</th>\n",
       "      <th>total_dirty_base</th>\n",
       "      <th>total_dirty_shocked</th>\n",
       "      <th>total_pnl_per_100_notional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-50</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1955.913753</td>\n",
       "      <td>4.814568e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-50</td>\n",
       "      <td>25</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1931.635425</td>\n",
       "      <td>2.386735e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-50</td>\n",
       "      <td>100</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1861.234675</td>\n",
       "      <td>-4.653340e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-25</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1931.635425</td>\n",
       "      <td>2.386735e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-25</td>\n",
       "      <td>25</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-25</td>\n",
       "      <td>100</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1838.553225</td>\n",
       "      <td>-6.921485e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1884.303751</td>\n",
       "      <td>-2.346432e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1816.251935</td>\n",
       "      <td>-9.151614e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1884.303751</td>\n",
       "      <td>-2.346432e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1861.234675</td>\n",
       "      <td>-4.653340e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1794.323494</td>\n",
       "      <td>-1.134446e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1861.234675</td>\n",
       "      <td>-4.653340e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1838.553225</td>\n",
       "      <td>-6.921485e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1907.768073</td>\n",
       "      <td>1772.760740</td>\n",
       "      <td>-1.350073e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rate_shock_bp  spread_shock_bp  total_dirty_base  total_dirty_shocked  \\\n",
       "0             -50                0       1907.768073          1955.913753   \n",
       "1             -50               25       1907.768073          1931.635425   \n",
       "2             -50              100       1907.768073          1861.234675   \n",
       "3             -25                0       1907.768073          1931.635425   \n",
       "4             -25               25       1907.768073          1907.768073   \n",
       "5             -25              100       1907.768073          1838.553225   \n",
       "6               0                0       1907.768073          1907.768073   \n",
       "7               0               25       1907.768073          1884.303751   \n",
       "8               0              100       1907.768073          1816.251935   \n",
       "9              25                0       1907.768073          1884.303751   \n",
       "10             25               25       1907.768073          1861.234675   \n",
       "11             25              100       1907.768073          1794.323494   \n",
       "12             50                0       1907.768073          1861.234675   \n",
       "13             50               25       1907.768073          1838.553225   \n",
       "14             50              100       1907.768073          1772.760740   \n",
       "\n",
       "    total_pnl_per_100_notional  \n",
       "0                 4.814568e+01  \n",
       "1                 2.386735e+01  \n",
       "2                -4.653340e+01  \n",
       "3                 2.386735e+01  \n",
       "4                -2.273737e-13  \n",
       "5                -6.921485e+01  \n",
       "6                 0.000000e+00  \n",
       "7                -2.346432e+01  \n",
       "8                -9.151614e+01  \n",
       "9                -2.346432e+01  \n",
       "10               -4.653340e+01  \n",
       "11               -1.134446e+02  \n",
       "12               -4.653340e+01  \n",
       "13               -6.921485e+01  \n",
       "14               -1.350073e+02  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined scenario runner\n",
    "\n",
    "def run_combined_rate_spread_scenarios(\n",
    "    base_curve: ZeroCurve,\n",
    "    corp_portfolio: pd.DataFrame,\n",
    "    val_date: pd.Timestamp,\n",
    "    settle: pd.Timestamp,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scenarios:\n",
    "      - Parallel rate shocks: -50, -25, +25, +50 (bp)\n",
    "      - Spread shocks: 0, +25, +100 (bp)\n",
    "      - Combine them into a grid and report total P&L\n",
    "    \"\"\"\n",
    "    settle = pd.Timestamp(settle)\n",
    "\n",
    "    base_prices = price_corporate_portfolio_vectorized(base_curve, corp_portfolio, val_date, settle)\n",
    "    base_total = base_prices[\"dirty\"].sum()\n",
    "\n",
    "    rate_shocks = [-50, -25, 0, 25, 50]\n",
    "    spread_shocks = [0, 25, 100]\n",
    "\n",
    "    rows = []\n",
    "    for r_bp in rate_shocks:\n",
    "        scurve = curve_from_shifted_zeros(base_curve, parallel_shift_bp(r_bp))\n",
    "\n",
    "        for s_bp in spread_shocks:\n",
    "            shocked_port = corp_portfolio.copy()\n",
    "            shocked_port[\"spread\"] = shocked_port[\"spread\"] + s_bp / 10000.0\n",
    "\n",
    "            shocked_prices = price_corporate_portfolio_vectorized(scurve, shocked_port, val_date, settle)\n",
    "            shocked_total = shocked_prices[\"dirty\"].sum()\n",
    "\n",
    "            rows.append({\n",
    "                \"rate_shock_bp\": r_bp,\n",
    "                \"spread_shock_bp\": s_bp,\n",
    "                \"total_dirty_base\": base_total,\n",
    "                \"total_dirty_shocked\": shocked_total,\n",
    "                \"total_pnl_per_100_notional\": shocked_total - base_total,\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    return out.sort_values([\"rate_shock_bp\", \"spread_shock_bp\"]).reset_index(drop=True)\n",
    "\n",
    "combo = run_combined_rate_spread_scenarios(curve, corp_portfolio_df, val_date, settle)\n",
    "combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "74dc722e-b8ed-44c8-9c71-ee30e00059fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>spread_shock_bp</th>\n",
       "      <th>0</th>\n",
       "      <th>25</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_shock_bp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-50</th>\n",
       "      <td>48.145680</td>\n",
       "      <td>2.386735e+01</td>\n",
       "      <td>-46.533397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-25</th>\n",
       "      <td>23.867352</td>\n",
       "      <td>-2.273737e-13</td>\n",
       "      <td>-69.214847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.346432e+01</td>\n",
       "      <td>-91.516137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-23.464322</td>\n",
       "      <td>-4.653340e+01</td>\n",
       "      <td>-113.444579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-46.533397</td>\n",
       "      <td>-6.921485e+01</td>\n",
       "      <td>-135.007333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "spread_shock_bp        0             25          100\n",
       "rate_shock_bp                                       \n",
       "-50              48.145680  2.386735e+01  -46.533397\n",
       "-25              23.867352 -2.273737e-13  -69.214847\n",
       " 0                0.000000 -2.346432e+01  -91.516137\n",
       " 25             -23.464322 -4.653340e+01 -113.444579\n",
       " 50             -46.533397 -6.921485e+01 -135.007333"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot table\n",
    "\n",
    "pivot = combo.pivot(index=\"rate_shock_bp\", columns=\"spread_shock_bp\", values=\"total_pnl_per_100_notional\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1996747-c4a2-4f21-b762-439ede2a0b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Spread DV01 (per 1bp): -0.9462587331993291\n",
      "Implied 25bp P&L from linear approx: -23.656468329983227\n",
      "Actual 25bp P&L: -23.46432230466108\n"
     ]
    }
   ],
   "source": [
    "# Portfolio spread DV01 (risk dashboard metric)\n",
    "\n",
    "def portfolio_spread_dv01(curve: ZeroCurve, corp_portfolio: pd.DataFrame, val_date: pd.Timestamp, settle: pd.Timestamp) -> float:\n",
    "    base = price_corporate_portfolio_vectorized(curve, corp_portfolio, val_date, settle)[\"dirty\"].sum()\n",
    "\n",
    "    bumped = corp_portfolio.copy()\n",
    "    bumped[\"spread\"] = bumped[\"spread\"] + 1/10000.0\n",
    "\n",
    "    shocked = price_corporate_portfolio_vectorized(curve, bumped, val_date, settle)[\"dirty\"].sum()\n",
    "    return shocked - base\n",
    "\n",
    "psdv01 = portfolio_spread_dv01(curve, corp_portfolio_df, val_date, settle)\n",
    "print(\"Portfolio Spread DV01 (per 1bp):\", psdv01)\n",
    "print(\"Implied 25bp P&L from linear approx:\", 25*psdv01)\n",
    "print(\"Actual 25bp P&L:\", spread_summary.loc[spread_summary[\"scenario\"]==\"SPR_+25bp_PnL\",\"total_pnl_per_100_notional\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc955f7c-7158-4eb5-a7cf-a8cdb4e5c1aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Combined Rate + Spread Scenario Table\n",
    "\n",
    "Our pivot:\n",
    "\n",
    "| Rate \\ Spread | 0bp    | +25bp  | +100bp  |\n",
    "| ------------- | ------ | ------ | ------- |\n",
    "| -50bp         | +48.15 | +23.87 | -46.53  |\n",
    "| -25bp         | +23.87 | ~0     | -69.21  |\n",
    "| 0             | 0      | -23.46 | -91.52  |\n",
    "| +25bp         | -23.46 | -46.53 | -113.44 |\n",
    "| +50bp         | -46.53 | -69.21 | -135.01 |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "### 1) Symmetry in rate-only direction\n",
    "\n",
    "In the spread = 0 column:\n",
    "\n",
    "* -50bp → +48.15\n",
    "* +50bp → -46.53\n",
    "\n",
    "That’s convexity asymmetry, just like in Step V.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Spread-only direction (rate = 0 row)\n",
    "\n",
    "* +25bp → -23.46\n",
    "* +100bp → -91.52\n",
    "\n",
    "Linear check:\n",
    "\n",
    "Spread DV01 ≈ -0.9463\n",
    "\n",
    "Linear 25bp approx:\n",
    "[\n",
    "25 \\times (-0.9463) = -23.66\n",
    "]\n",
    "\n",
    "Actual:\n",
    "-23.46\n",
    "\n",
    "That’s extremely close.\n",
    "\n",
    "So:\n",
    "\n",
    "* Spread duration implementation is correct\n",
    "* Spread is applied to all cashflows\n",
    "* Spread convexity effect is small for 25bp\n",
    "\n",
    "That’s exactly what we expect.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Cross interaction\n",
    "\n",
    "We notice that:\n",
    "\n",
    "Rate +25bp & Spread +25bp → -46.53\n",
    "\n",
    "Which is approximately:\n",
    "\n",
    "[\n",
    "-23.46 + (-23.46) ≈ -46.92\n",
    "]\n",
    "\n",
    "Actual: -46.53\n",
    "\n",
    "Small nonlinear interaction from convexity.\n",
    "\n",
    "That means:\n",
    "\n",
    "* Rate and spread risk are approximately additive for small shocks.\n",
    "* Second-order effects exist but are modest.\n",
    "\n",
    "That is the expected risk behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562c434-ba26-4beb-b85a-c5c5410753d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **VIII. Portfolio Risk Dashboard**\n",
    "\n",
    "This dashboard summarizes the portfolio’s:\n",
    "\n",
    "- Market value\n",
    "- Parallel DV01 (rate risk)\n",
    "- Convexity\n",
    "- Key Rate Duration (term structure exposure)\n",
    "- Spread DV01 (credit risk)\n",
    "- Top contributors to rate and spread risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4c5dab0-7483-4701-ad24-41ffa0bdd9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Market Value (per 100 notional sum): 1907.7680728781722\n",
      "Parallel DV01: -1.0302933377672616\n",
      "Spread DV01: -0.9462587331993291\n"
     ]
    }
   ],
   "source": [
    "# Portoflio totals\n",
    "\n",
    "# Market value\n",
    "base_total = price_corporate_portfolio_vectorized(curve, corp_portfolio_df, val_date, settle)[\"dirty\"].sum()\n",
    "\n",
    "parallel_dv01 = par_dv01  # from earlier\n",
    "spread_dv01_total = psdv01\n",
    "\n",
    "print(\"Total Market Value (per 100 notional sum):\", base_total)\n",
    "print(\"Parallel DV01:\", parallel_dv01)\n",
    "print(\"Spread DV01:\", spread_dv01_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca43fbf1-15db-4342-8d5d-0acfe06fdfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>knot_date</th>\n",
       "      <th>tau_years</th>\n",
       "      <th>bucket_dv01</th>\n",
       "      <th>bucket_dv01_pct_of_total</th>\n",
       "      <th>abs_exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2036-02-15</td>\n",
       "      <td>10.010959</td>\n",
       "      <td>-0.557962</td>\n",
       "      <td>0.541513</td>\n",
       "      <td>0.557962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2031-02-15</td>\n",
       "      <td>5.008219</td>\n",
       "      <td>-0.352736</td>\n",
       "      <td>0.342337</td>\n",
       "      <td>0.352736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2028-02-15</td>\n",
       "      <td>2.005479</td>\n",
       "      <td>-0.093303</td>\n",
       "      <td>0.090553</td>\n",
       "      <td>0.093303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2027-02-12</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>-0.025649</td>\n",
       "      <td>0.024893</td>\n",
       "      <td>0.025649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-08-14</td>\n",
       "      <td>0.498630</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-20</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-05-15</td>\n",
       "      <td>0.249315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-03-13</td>\n",
       "      <td>0.076712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  knot_date  tau_years  bucket_dv01  bucket_dv01_pct_of_total  \\\n",
       "7             7 2036-02-15  10.010959    -0.557962                  0.541513   \n",
       "6             6 2031-02-15   5.008219    -0.352736                  0.342337   \n",
       "5             5 2028-02-15   2.005479    -0.093303                  0.090553   \n",
       "4             4 2027-02-12   0.997260    -0.025649                  0.024893   \n",
       "3             3 2026-08-14   0.498630    -0.002396                  0.002326   \n",
       "0             0 2026-02-20   0.019178     0.001671                 -0.001621   \n",
       "2             2 2026-05-15   0.249315     0.000000                 -0.000000   \n",
       "1             1 2026-03-13   0.076712     0.000000                 -0.000000   \n",
       "\n",
       "   abs_exposure  \n",
       "7      0.557962  \n",
       "6      0.352736  \n",
       "5      0.093303  \n",
       "4      0.025649  \n",
       "3      0.002396  \n",
       "0      0.001671  \n",
       "2      0.000000  \n",
       "1      0.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Key Rate bucket exposure table\n",
    "\n",
    "bucket_table[\"abs_exposure\"] = bucket_table[\"bucket_dv01\"].abs()\n",
    "bucket_table.sort_values(\"abs_exposure\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "62222d73-642a-48a0-b58c-50b1e7943a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>dirty_base</th>\n",
       "      <th>dirty_up1bp</th>\n",
       "      <th>dv01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOND_012</td>\n",
       "      <td>109.187743</td>\n",
       "      <td>109.101494</td>\n",
       "      <td>-0.086249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>124.890127</td>\n",
       "      <td>124.804022</td>\n",
       "      <td>-0.086106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>94.504154</td>\n",
       "      <td>94.425087</td>\n",
       "      <td>-0.079067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BOND_015</td>\n",
       "      <td>103.963170</td>\n",
       "      <td>103.886391</td>\n",
       "      <td>-0.076779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOND_017</td>\n",
       "      <td>119.227594</td>\n",
       "      <td>119.151886</td>\n",
       "      <td>-0.075708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bond_id  dirty_base  dirty_up1bp      dv01\n",
       "12  BOND_012  109.187743   109.101494 -0.086249\n",
       "6   BOND_006  124.890127   124.804022 -0.086106\n",
       "0   BOND_000   94.504154    94.425087 -0.079067\n",
       "15  BOND_015  103.963170   103.886391 -0.076779\n",
       "17  BOND_017  119.227594   119.151886 -0.075708"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 bonds by rate DV01\n",
    "\n",
    "rate_risk = compute_portfolio_dv01(curve, portfolio_df, val_date, settle)\n",
    "rate_risk_sorted = rate_risk.sort_values(\"dv01\", key=lambda x: x.abs(), ascending=False)\n",
    "rate_risk_sorted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9818b7f-6d8a-4822-97aa-4ca6c4c69a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bond_id</th>\n",
       "      <th>base</th>\n",
       "      <th>shocked</th>\n",
       "      <th>spread_dv01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOND_006</td>\n",
       "      <td>121.042595</td>\n",
       "      <td>120.959599</td>\n",
       "      <td>-0.082996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOND_000</td>\n",
       "      <td>90.017060</td>\n",
       "      <td>89.942189</td>\n",
       "      <td>-0.074870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOND_012</td>\n",
       "      <td>95.168889</td>\n",
       "      <td>95.095391</td>\n",
       "      <td>-0.073498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOND_003</td>\n",
       "      <td>98.224779</td>\n",
       "      <td>98.151618</td>\n",
       "      <td>-0.073161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOND_017</td>\n",
       "      <td>108.961836</td>\n",
       "      <td>108.893607</td>\n",
       "      <td>-0.068229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bond_id        base     shocked  spread_dv01\n",
       "6   BOND_006  121.042595  120.959599    -0.082996\n",
       "0   BOND_000   90.017060   89.942189    -0.074870\n",
       "12  BOND_012   95.168889   95.095391    -0.073498\n",
       "3   BOND_003   98.224779   98.151618    -0.073161\n",
       "17  BOND_017  108.961836  108.893607    -0.068229"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 bonds by spread DV01\n",
    "\n",
    "def compute_spread_dv01_per_bond(curve, corp_portfolio, val_date, settle):\n",
    "    base = price_corporate_portfolio_vectorized(curve, corp_portfolio, val_date, settle)[[\"bond_id\",\"dirty\"]]\n",
    "    base = base.rename(columns={\"dirty\":\"base\"})\n",
    "\n",
    "    bumped = corp_portfolio.copy()\n",
    "    bumped[\"spread\"] = bumped[\"spread\"] + 1/10000.0\n",
    "\n",
    "    shocked = price_corporate_portfolio_vectorized(curve, bumped, val_date, settle)[[\"bond_id\",\"dirty\"]]\n",
    "    shocked = shocked.rename(columns={\"dirty\":\"shocked\"})\n",
    "\n",
    "    tmp = base.merge(shocked, on=\"bond_id\")\n",
    "    tmp[\"spread_dv01\"] = tmp[\"shocked\"] - tmp[\"base\"]\n",
    "    return tmp\n",
    "\n",
    "spread_risk = compute_spread_dv01_per_bond(curve, corp_portfolio_df, val_date, settle)\n",
    "spread_risk.sort_values(\"spread_dv01\", key=lambda x: x.abs(), ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200342a-3811-40e6-9d3e-f07b319679f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Portfolio Risk Analysis — Institutional Valuation Report\n",
    "\n",
    "## 1. Portfolio Overview\n",
    "\n",
    "### Total Market Value\n",
    "\n",
    "Total dirty market value (per 100 notional sum):\n",
    "\n",
    "$$\n",
    "\\text{MV} = 1907.77\n",
    "$$\n",
    "\n",
    "With 20 bonds in the portfolio, the average dirty price is approximately:\n",
    "\n",
    "$$\n",
    "\\frac{1907.77}{20} \\approx 95.39\n",
    "$$\n",
    "\n",
    "This is economically reasonable given the presence of positive credit spreads across the portfolio.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Aggregate Risk Metrics\n",
    "\n",
    "### Parallel DV01 (Rate Risk)\n",
    "\n",
    "$$\n",
    "DV01_{\\text{parallel}} = -1.0303\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- A +1bp parallel upward shift in the risk-free curve reduces total portfolio value by approximately **1.03** per 100 notional.\n",
    "- A +100bp rate shock would imply a linear loss of approximately:\n",
    "\n",
    "$$\n",
    "-1.0303 \\times 100 \\approx -103.03\n",
    "$$\n",
    "\n",
    "The sign and magnitude are consistent with a long-duration fixed-income portfolio.\n",
    "\n",
    "---\n",
    "\n",
    "### Spread DV01 (Credit Risk)\n",
    "\n",
    "$$\n",
    "DV01_{\\text{spread}} = -0.9463\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- A +1bp widening in credit spreads reduces portfolio value by approximately **0.95** per 100 notional.\n",
    "- Spread risk magnitude is comparable to rate risk, indicating material exposure to credit conditions.\n",
    "\n",
    "Linear 25bp check:\n",
    "\n",
    "$$\n",
    "25 \\times (-0.9463) = -23.66\n",
    "$$\n",
    "\n",
    "Observed P&L under +25bp spread shock:\n",
    "\n",
    "$$\n",
    "-23.46\n",
    "$$\n",
    "\n",
    "The close match confirms:\n",
    "\n",
    "- Correct application of spreads to **all cashflows**\n",
    "- Proper settlement-adjusted spread discounting\n",
    "- Minimal second-order (spread convexity) distortion for small shocks\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Key Rate Duration (Term Structure Decomposition)\n",
    "\n",
    "Key Rate Duration was computed using partition-of-unity hat basis functions to ensure:\n",
    "\n",
    "$$\n",
    "\\sum_k KRD_k \\approx DV01_{\\text{parallel}}\n",
    "$$\n",
    "\n",
    "Reconciliation:\n",
    "\n",
    "- Sum of bucket DV01s: −1.03038  \n",
    "- Parallel DV01: −1.03029  \n",
    "- Difference: ~8.3e−05 (numerical tolerance)\n",
    "\n",
    "This confirms internal consistency.\n",
    "\n",
    "### Bucket Exposure Breakdown\n",
    "\n",
    "| Maturity | Tau (years) | Bucket DV01 |\n",
    "|-----------|-------------|-------------|\n",
    "| 2036 | 10.01 | −0.558 |\n",
    "| 2031 | 5.01 | −0.353 |\n",
    "| 2028 | 2.01 | −0.093 |\n",
    "| 2027 | 1.00 | −0.026 |\n",
    "| Short-end | <0.5 | ~0 |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- Over 85% of total rate risk resides in the **5–10 year sector**.\n",
    "- Short-end exposure is negligible.\n",
    "- Portfolio is structurally long duration at the intermediate-to-long end.\n",
    "\n",
    "This aligns with earlier steepener/flattener scenario behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Concentration Risk — Top Contributors\n",
    "\n",
    "### Top 5 Bonds by Rate DV01\n",
    "\n",
    "Largest contributors to rate sensitivity:\n",
    "\n",
    "- BOND_012: −0.086\n",
    "- BOND_006: −0.086\n",
    "- BOND_000: −0.079\n",
    "- BOND_015: −0.077\n",
    "- BOND_017: −0.076\n",
    "\n",
    "These bonds likely:\n",
    "- Have longer maturities\n",
    "- Exhibit higher duration\n",
    "- Dominate term-structure risk\n",
    "\n",
    "---\n",
    "\n",
    "### Top 5 Bonds by Spread DV01\n",
    "\n",
    "Largest contributors to credit sensitivity:\n",
    "\n",
    "- BOND_006: −0.083\n",
    "- BOND_000: −0.075\n",
    "- BOND_012: −0.073\n",
    "- BOND_003: −0.073\n",
    "- BOND_017: −0.068\n",
    "\n",
    "Observation:\n",
    "\n",
    "Several bonds dominate **both rate and spread risk**, indicating concentration of long-end credit exposure.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Combined Rate + Spread Scenario Interpretation\n",
    "\n",
    "Selected combined scenarios:\n",
    "\n",
    "| Rate Shock | Spread Shock | Total P&L |\n",
    "|------------|--------------|-----------|\n",
    "| -50bp | 0bp | +48.15 |\n",
    "| 0bp | +25bp | -23.46 |\n",
    "| +25bp | +25bp | -46.53 |\n",
    "| +50bp | +100bp | -135.01 |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- Rate and spread risks are approximately additive for small shocks.\n",
    "- Risk-off scenarios (rates ↑ + spreads ↑) produce significant downside.\n",
    "- Spread shocks dominate for large widening scenarios.\n",
    "- Convexity introduces mild asymmetry in rate-only movements.\n",
    "\n",
    "This behavior is consistent with institutional fixed-income risk models.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Structural Risk Observations\n",
    "\n",
    "1. Rate and spread risk magnitudes are comparable.\n",
    "2. Risk is heavily concentrated in intermediate-to-long maturities.\n",
    "3. Portfolio is convexity-positive.\n",
    "4. Scenario results reconcile with DV01 approximations.\n",
    "5. Key Rate Duration correctly decomposes parallel DV01.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The portfolio analytics framework now supports:\n",
    "\n",
    "- Zero curve bootstrapping\n",
    "- Settlement-aware clean/dirty pricing\n",
    "- Vectorized portfolio valuation\n",
    "- Parallel DV01 and convexity\n",
    "- Key Rate Duration decomposition\n",
    "- Corporate spread discounting (Z-spread style)\n",
    "- Spread DV01\n",
    "- Combined rate + spread stress scenarios\n",
    "- Risk concentration reporting\n",
    "\n",
    "The analytics are internally consistent, economically interpretable, and structured in a way consistent with institutional valuation infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9bf64-06d2-4ea5-9ef3-fe3c86f2108a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fixed_income_env]",
   "language": "python",
   "name": "conda-env-fixed_income_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
